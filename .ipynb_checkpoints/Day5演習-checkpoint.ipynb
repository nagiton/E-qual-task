{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEQEe0luCvEj"
   },
   "source": [
    "# 全人類がわかるディープラーニング Day5演習\n",
    "\n",
    "## 概要\n",
    "\n",
    "本演習では自然言語処理に代表される系列データを扱うためのネットワークであるRNNやその派生ネットワークによる学習を穴埋め形式で実装します。なお、予め用意されたコードはそのまま使用し、指示された穴埋め部を編集してください。\n",
    "演習問題文は<font color=\"Red\">赤字</font>です。このファイルは必ず最後までコードをすべて実行し、「最後までコードが実行可能」・「学習結果の出力がある」・「学習が成功している」の３つを満たした状態で提出してください。\n",
    "\n",
    "所要時間：3~8時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sm7ZvF2SCvEk"
   },
   "source": [
    "### ライブラリのインポート\n",
    "\n",
    "必要なライブラリをインポートします。エラーになる場合は該当するものをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-thDJ_VCvEl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 乱数シードを指定\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2zc3aStCvEn"
   },
   "source": [
    "## 基本的関数、アルゴリズムの実装\n",
    "\n",
    "- SGD\n",
    "- Adam\n",
    "- sigmoid\n",
    "- softmax\n",
    "- clip_grads\n",
    "    勾配クリッピング用の関数。実装自体は単純なので省略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQOKfGRvfqfd"
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(x.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCuXbNbACvEo"
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]\n",
    "            \n",
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
    "            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-iaf2EbCvEp"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQF7Uc98CvFM"
   },
   "outputs": [],
   "source": [
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCuZ1sRxfqfk"
   },
   "source": [
    "## 自然言語処理用のレイヤークラス定義\n",
    "### Embedding クラス\n",
    "- 自然言語処理において、単語をベクトル（分散表現）に変換する前処理(Embeddingと言われる)が必須となる。\n",
    "- Embeddingクラスは入力されてきた単語列をべクトルに変換する。\n",
    "- 単語はID化されているため、一つのデータ（文章）は`[3,0,4,1]`のようになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cS38fL6wfqfl"
   },
   "source": [
    "例えば\n",
    "\n",
    "単語 0 を `[0.5, 1.2]`\n",
    "\n",
    "単語 1 を`[-1.4, 0.7]`\n",
    "\n",
    "単語 2 を` [2.5, -0.9]`\n",
    "\n",
    "単語 3 を`[5.6, 9.8]`\n",
    "\n",
    "単語 4 を`[-2.3, -0.8]`\n",
    "\n",
    "に変換するようなEmbed 層を用意する場合、\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "0.5 & 1.2 \\\\\n",
    "-1.4 & 0.7 \\\\\n",
    "2.5 & -0.9 \\\\\n",
    "5.6 & 9.8 \\\\\n",
    "-2.3 & -0.8 \\\\\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "のような変換行列を用意し、入力の単語IDをindexとして各単語を変換してやれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYYi0RG1fqfl"
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "\n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMU5mYpgfqfo"
   },
   "source": [
    "逆伝播については、変換行列に対して、入力時の単語に相当する箇所に伝播してきた勾配を足し合わせてやれば良いため、`np.add.at` を使用すれば良い。\n",
    "\n",
    "`np.add.at(dW, self.idx, dout)` によって、`dW[self.idx]`に対して`dout`が加えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iggs_wFlfqfo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.6,  9.8],\n",
       "       [ 0.5,  1.2],\n",
       "       [-2.3, -0.8],\n",
       "       [-1.4,  0.7]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([[0.5, 1.2],\n",
    "              [-1.4, 0.7],\n",
    "              [2.5, -0.9],\n",
    "              [5.6, 9.8],\n",
    "              [-2.3, -0.8]])\n",
    "embedder_example = Embedding(w)\n",
    "minibatch_example = np.array([3,0,4,1])\n",
    "embedder_example.forward(minibatch_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gt7tXDMSfqfq"
   },
   "source": [
    "## Time層の実装\n",
    "RNNで系列データを扱う際、例えば時刻tでの入力データ$x_t$を順伝播させたのちに隠れ層の値$h_t$を得、次の時刻t+1での入力データ$x_{t+1}$を順伝播させ……というように、データを時刻ごとに分割してからRNN層やAffine層、Embedding層に入力するという形式を取らなくてはならず、系列データを一々分割し、各時刻データに対して順伝播をさせるというように手間がかかってしまう。\n",
    "\n",
    "そのため、全時刻に渡って一度に順伝播などの処理を行ってくれるように、ユニットを時刻方向に繋げ一つのユニットとすることを考える。\n",
    "ここではこのように時系列データをまとめて扱う層のことを`TimeEmbedding`や`TimeAffine`のように、各クラス名に`Time`を付けて表すことにする。\n",
    "\n",
    "<img src= time_layer_image.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--n34DcBfqfr"
   },
   "source": [
    "### TimeEmbedding クラス\n",
    "\n",
    "TimeEmbedding クラスの入力として想定する形式は、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）\n",
    "\n",
    "であり、各単語をD次元ベクトルに変換するとすれば出力は\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（次元数D）\n",
    "\n",
    "となる。\n",
    "\n",
    "系列に発展させた形としては、順伝播/逆伝播ともに時刻数tをfor文で順に処理してやれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO8XOzIWCvEr"
   },
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TD723Fyefqft"
   },
   "source": [
    "### TimeAffine クラス\n",
    "TimeAffineクラスの入力として想定する形式は、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（単語ベクトル次元数）\n",
    "\n",
    "であり、このAffineクラスによって単語ベクトル次元数$D_1$から$D_2$に変換すると考えれば、サイズ$D_1 \\times D_2$ の重み行列を用意し、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（$D_2$）\n",
    "\n",
    "が出力となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8oo7Gr_CvEu"
   },
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0KBTEUmfqfv"
   },
   "source": [
    "### TimeSoftmaxWithLoss クラス\n",
    "TimeSoftmaxWithLoss クラスの入力として想定する形式は、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（次元数）\n",
    "\n",
    "であり、この次元数についてsoftmax関数により変換を行うものと考える。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3Sr6xoPCvEs"
   },
   "outputs": [],
   "source": [
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 教師ラベルがone-hotベクトルの場合\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        # バッチ分と時系列分をまとめる（reshape）\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= len(ts)\n",
    "\n",
    "        self.cache = (ts, ys, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= len(ys)\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIYsJAPZCvEy"
   },
   "source": [
    "## データセット用意\n",
    "\n",
    "ptbという英語の文章を集めたデータセットを用意します。\n",
    "\n",
    "このデータセットについて、単語を順に入力していき、次の単語を予測するというタスクを解かせてみます。\n",
    "本来であれば訓練データで学習をさせた後テストデータで検証を行いますが、簡単のため今回は学習のみを行い、テストによる検証は行いません。\n",
    "\n",
    "こちらのデータセットを用いて解いていくタスクは実践的なタスクと言うよりは、RNNの実装がうまくいっており、学習が成功することを確認するためのものとなります。\n",
    "\n",
    "データセットの用意の部分ですので、コードは読み飛ばしていただいても構いません。\n",
    "\n",
    "行っている処理の流れを示すと、\n",
    "1. データのダウンロード\n",
    "1. 単語とIDの変換ディクショナリの作成\n",
    "1. ダウンロードしてきた単語列のデータに対し、全単語をIDに変換\n",
    "\n",
    "と言う流れになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8psB7A9CvEz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import pickle\n",
    "\n",
    "url_base = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\n",
    "key_file = {\n",
    "    'train':'ptb.train.txt'\n",
    "}\n",
    "save_file = {\n",
    "    'train':'ptb.train.npy'\n",
    "}\n",
    "vocab_file = 'ptb.vocab.pkl'\n",
    "\n",
    "def _download(file_name):\n",
    "    file_path = './' + file_name\n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    print('Downloading ' + file_name + ' ... ')\n",
    "\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "    except urllib.error.URLError:\n",
    "        import ssl\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "def load_vocab():\n",
    "    vocab_path = './' + vocab_file\n",
    "\n",
    "    if os.path.exists(vocab_path):\n",
    "        with open(vocab_path, 'rb') as f:\n",
    "            word_to_id, id_to_word = pickle.load(f)\n",
    "        return word_to_id, id_to_word\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    data_type = 'train'\n",
    "    file_name = key_file[data_type]\n",
    "    file_path = './' + file_name\n",
    "\n",
    "    _download(file_name)\n",
    "\n",
    "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in word_to_id:\n",
    "            tmp_id = len(word_to_id)\n",
    "            word_to_id[word] = tmp_id\n",
    "            id_to_word[tmp_id] = word\n",
    "\n",
    "    with open(vocab_path, 'wb') as f:\n",
    "        pickle.dump((word_to_id, id_to_word), f)\n",
    "\n",
    "    return word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9nT8sbgCvE1"
   },
   "outputs": [],
   "source": [
    "def load_ptb(data_type='train'):\n",
    "    save_path = './' + save_file[data_type]\n",
    "    word_to_id, id_to_word = load_vocab()\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        corpus = np.load(save_path)\n",
    "        return corpus, word_to_id, id_to_word\n",
    "\n",
    "    file_name = key_file[data_type]\n",
    "    file_path = './' + file_name\n",
    "    _download(file_name)\n",
    "\n",
    "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    np.save(save_path, corpus)\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BCCI4Lyfqf2"
   },
   "source": [
    "読み込んだデータを学習用に分割します。\n",
    "そのままではデータ数が大きすぎるので、前から1000単語のみを使用します。\n",
    "\n",
    "xsには0番目から998番目までの単語IDが、tsには1番目から999番目までの単語IDが格納されています。解くべきタスクとしては、xsのi番目までの単語IDを入力として、i+1番目の単語、即ちtsのi番目の単語を予測するというものになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o98awk5Mfqf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocabulary size: 418\n"
     ]
    }
   ],
   "source": [
    "# 学習データの読み込み（データセットを小さくする）\n",
    "corpus, word_to_id, id_to_word = load_ptb('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "data_size = len(xs)\n",
    "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ii6uCudrCvE4"
   },
   "source": [
    "## ネットワーク定義\n",
    "### RNNクラス\n",
    "問1-1. <font color=\"Red\">RNNレイヤーを表すクラス RNNクラスを完成させてください。</font>\n",
    "\n",
    "  RNNクラスは以下に従って定義します。\n",
    "    \n",
    "  - `Wx`, `Wh`はそれぞれ順伝播時に入力、前時刻隠れ層にかかる重み行列\n",
    "  - 活性化関数は `tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKhQecjFCvE4"
   },
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params \n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b ######問1.1.1######\n",
    "        h_next = np.tanh(t) \n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next * (1.0-h_next**2) ######問1.1.3######\n",
    "        db = np.sum(dt,axis=0) ######問1.1.4######\n",
    "        dWh = np.dot(h_prev.T,dt) ######問1.1.5######\n",
    "        dh_prev = np.dot(dt,Wh.T) ######問1.1.6######\n",
    "        dWx = np.dot(x.T,dt) ######問1.1.7###### #dt.shape == (20,100)\n",
    "        dx = np.dot(dt,Wx.T) ######問1.1.8######\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5byKc-5Pfqf6"
   },
   "source": [
    "### TimeRNNクラス\n",
    "問1-2. <font color=\"Red\">TimeRNNクラスを完成させてください。</font>\n",
    "\n",
    "TimeRNNクラスの仕様は以下の通りです。\n",
    "  \n",
    "  1. 順伝播\n",
    "      \n",
    "      - 時刻`t`を時系列分だけfor文でループさせます\n",
    "      - 順伝播により計算した隠れ層をメンバ変数`h`として格納します\n",
    "      - 順伝播時には<font color=\"Red\">メンバ変数`h`と入力データのうち時刻`t`に対応するデータを使用して</font>出力を計算します\n",
    "      \n",
    "  1. 逆伝播\n",
    "      - 今回のタスクにおいては、全時刻において次単語を予測し、その予測について損失が計算される、即ち勾配が入力されてくるため、逆伝播の入力`dhs`の想定される形は（バッチサイズ）×（単語数=時刻数）×（RNNの出力次元数）となります\n",
    "      - 各時刻において、<font color=\"Red\">次の時刻から伝播してきた勾配と現時刻における出力から伝播してきた勾配との和</font>を入力としてRNN層の逆伝播を計算します\n",
    "  \n",
    "また、今回のタスクにおける少々特殊な処理に対応するためや、この後実装する別タスクにおいても汎用的に使用するためにいくつか細かい仕様を加えます。\n",
    "実装上の細かい仕様のため、問題にはしていませんが、参考にしてください。\n",
    "\n",
    "  1. stateful\n",
    "    - 今回のタスクにおける目的はRNNネットワークが正しく実装できていることです。簡単に学習が成功していることを確認するため、（実務的にも用いられることのある）Truncated BPTT という少々特殊な処理を行います。\n",
    "    - 今回のタスクでは、入力する単語数（時刻数）として1000程度を入力していますが、この単語全てを順伝播させて逆伝播を計算し、ようやくパラメータ更新を1度行うというのでは効率が悪いため、順伝播は1000単語で行うものの逆伝播を5単語程度で区切って行う Truncated BPTT という方式を取っています。\n",
    "      1. まず、連続する5単語（例えば1~5番）を入力として順伝播・逆伝播・パラメータ更新を行います。\n",
    "      1. その際、順伝播の最終時刻における隠れ層`h`の値をメンバ変数として保持しておきます。\n",
    "      1. 次に5単語（先の例では6~10番）を入力として順伝播・逆伝播・パラメータ更新を行いますが、その際に初期入力の`h`を0で初期化せず、前から保持しているメンバ変数`h`の値をそのまま使用します。\n",
    "      1. このことにより、逆伝播は5単語単位で行われますが、順伝播は最初の単語から順にずっと計算されてきた値を使用することができます。\n",
    "      1. `stateful`がTrueの際にこのメンバ変数`h`の保持を行います。Falseの場合には`forward`関数が呼ばれるたびに`h`がリセット、即ち0で初期化されます。\n",
    "    \n",
    "  1. set_state\n",
    "    - 内部状態`h`を外から設定するための関数です。\n",
    "  \n",
    "  1. reset_state\n",
    "    - 内部状態`h`を外から削除するための関数です。\n",
    "  \n",
    "  1. params や grads としてパラメータ・勾配をまとめる\n",
    "    - 後でネットワーククラスを定義した際に、パラメータ更新などを楽に実行するための処理です。\n",
    "  1. backward における入力dhsの次元数による場合分け\n",
    "    - 今回のタスクでは全時刻において勾配が逆伝播してくるため、`dhs`の想定される形は（バッチサイズN）×（単語数=時刻数T）×（RNNの出力次元数H）となりますが、この後別のタスクを解く際には、全時刻ではなく最終時刻の出力のみから勾配が伝播してきます。\n",
    "    - この場合、dhsの次元数が違うため三次元に拡張することが必要になります。\n",
    "    - 最終時刻の出力のみから伝播してきたdhs の形は`(N,T,D)`のうち、`(N,D)`となっています。\n",
    "    - 最終時刻以外の勾配については何も伝播してきていないことから、全て0とすることで問題なく計算がなされます。\n",
    "    - 以上のことから、まず`np.zeros((N,T,D))`によって勾配の形を整え、その勾配の`[:,-1,:]`に対して入力された最終時刻における勾配を代入することで変わらず逆伝播を行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHobocVhCvE6"
   },
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self,input_size, output_size, stateful=False):\n",
    "        D, H = input_size, output_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        b = np.zeros(H).astype('f')\n",
    "\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        self.input_shapes = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        self.input_shapes = [N,T,D]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:,t,:], self.h) ######問1.2.1######\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = self.input_shapes\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        if dhs.ndim == 2:\n",
    "            temp = np.zeros((N,T,H))\n",
    "            temp[:,-1,:] = dhs\n",
    "            dhs = temp\n",
    "        \n",
    "        N, T, H = dhs.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:,t,:]+dh) ######問1.2.2######\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUClvI5jfqf9"
   },
   "source": [
    "### SimpleRnnNetwork クラス\n",
    "バッチサイズN、単語数T、単語の種類数V、embedにより単語をベクトル化した際の次元数D、RNNによる出力次元数Hとします。\n",
    "\n",
    "入力されてくるデータのサイズは`(N,T)`であり\n",
    "\n",
    "TimeEmbedding層により`(N,T,D)`に変換\n",
    "\n",
    "TimeRNN層により`(N,T,H)`に変換\n",
    "\n",
    "TimeAffine層により`(N,T,V)`に変換した後、V次元の中で最大のものを予測単語IDとして出力します。\n",
    "損失については、Softmaxを使用してV種類の各単語について確率値を出力し、クロスエントロピーで計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIN7sid8CvE8"
   },
   "outputs": [],
   "source": [
    "class SimpleRnnNetwork:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(D, H, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nb0ciPJJfqgA"
   },
   "source": [
    "### ハイパーパラメータや学習用データセットの用意\n",
    "\n",
    "バッチサイズ10のミニバッチを作成するため、offsets や time_idx などを使用します。\n",
    "細かい挙動まで追う必要はありませんが、Truncated BPTT を行うため、バッチサイズ10, 単語数5のミニバッチを作成したあと、通常のようにまたランダムに連続した5単語を取るのではなく、先のミニバッチから連続した5単語をミニバッチとして選択する必要があります。\n",
    "\n",
    "例として簡単のために単語数100個、バッチサイズ2とした場合を考えます。\n",
    "\n",
    "1エポック目でのミニバッチ選択を追うと、\n",
    "\n",
    "```\n",
    "0番目の単語-1番目の単語-2番目の単語-3番目の単語-4番目の単語\n",
    "49番目の単語-50番目の単語-51番目の単語-52番目の単語-53番目の単語\n",
    "```\n",
    "    ↓\n",
    "```\n",
    "5番目の単語-6番目の単語-7番目の単語-8番目の単語-9番目の単語\n",
    "54番目の単語-55番目の単語-56番目の単語-57番目の単語-58番目の単語\n",
    "```\n",
    "    ↓\n",
    "    ……\n",
    "    \n",
    "と言うようにミニバッチ内の各データについて連続して単語を選択しています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OX0jXUwCvE9"
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "batch_size = 20 #10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5 \n",
    "lr = 10 #0.1\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Xt6DtJDCvFB"
   },
   "source": [
    "## 学習、評価\n",
    "perplexity で評価を行います。\n",
    "\n",
    "40エポックでperplexityが一桁程度まで低下していれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-Gg-4OifqgF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | perplexity 383.29\n",
      "| epoch 2 | perplexity 404.38\n",
      "| epoch 3 | perplexity 495.07\n",
      "| epoch 4 | perplexity 390.11\n",
      "| epoch 5 | perplexity 372.79\n",
      "| epoch 6 | perplexity 506.35\n",
      "| epoch 7 | perplexity 479.50\n",
      "| epoch 8 | perplexity 432.91\n",
      "| epoch 9 | perplexity 360.85\n",
      "| epoch 10 | perplexity 372.38\n",
      "| epoch 11 | perplexity 415.85\n",
      "| epoch 12 | perplexity 354.59\n",
      "| epoch 13 | perplexity 358.59\n",
      "| epoch 14 | perplexity 324.91\n",
      "| epoch 15 | perplexity 304.62\n",
      "| epoch 16 | perplexity 279.87\n",
      "| epoch 17 | perplexity 241.67\n",
      "| epoch 18 | perplexity 206.49\n",
      "| epoch 19 | perplexity 199.07\n",
      "| epoch 20 | perplexity 145.76\n",
      "| epoch 21 | perplexity 117.35\n",
      "| epoch 22 | perplexity 87.93\n",
      "| epoch 23 | perplexity 63.97\n",
      "| epoch 24 | perplexity 48.82\n",
      "| epoch 25 | perplexity 36.44\n",
      "| epoch 26 | perplexity 28.13\n",
      "| epoch 27 | perplexity 24.34\n",
      "| epoch 28 | perplexity 18.15\n",
      "| epoch 29 | perplexity 15.65\n",
      "| epoch 30 | perplexity 12.09\n",
      "| epoch 31 | perplexity 10.16\n",
      "| epoch 32 | perplexity 7.97\n",
      "| epoch 33 | perplexity 7.08\n",
      "| epoch 34 | perplexity 5.50\n",
      "| epoch 35 | perplexity 4.71\n",
      "| epoch 36 | perplexity 4.46\n",
      "| epoch 37 | perplexity 3.80\n",
      "| epoch 38 | perplexity 3.53\n",
      "| epoch 39 | perplexity 3.53\n",
      "| epoch 40 | perplexity 3.07\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRnnNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "#model = LSTMNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "rnn_ppl_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    rnn_ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyzEKNaLCvFD"
   },
   "source": [
    "## LSTM\n",
    "### LSTMクラス\n",
    "\n",
    "問2-1. <font color=\"Red\">LSTMクラスを完成させてください。</font>\n",
    "\n",
    "LSTMクラスの仕様はRNNクラスとほとんど同じです。\n",
    "\n",
    "各ゲートの計算と通常の順伝播の計算に使用するパラメータを行列にまとめ、一行で計算できるように、変数Aを用いて実装しています。\n",
    "\n",
    "f,g,i,o はそれぞれ、忘却ゲート・入力からの順伝播・入力ゲート・出力ゲートを表しています。\n",
    "\n",
    "<img src=\"lstm_image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "972frd2QCvFE"
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b ######問2.1.1######\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f) ######問2.1.2######\n",
    "        g = np.tanh(g) ######問2.1.3######\n",
    "        i = sigmoid(i) ######問2.1.4######\n",
    "        o = sigmoid(o) ######問2.1.5######\n",
    "\n",
    "        c_next = f * c_prev + g * i ######問2.1.6######\n",
    "        h_next = o * np.tanh(c_next) ######問2.1.7######\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2) ######問2.1.8######\n",
    "\n",
    "        dc_prev = ds * f ######問2.1.9######\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x75K80tXfqgJ"
   },
   "source": [
    "### TimeLSTMクラス\n",
    "\n",
    "問2-2. <font color=\"Red\">TimeLSTMクラスを完成させてください。</font>\n",
    "\n",
    "TimeRNNと同じように実装します。\n",
    "\n",
    "SimpleRNN のときと違って、重みの初期化に注意を払う必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXkWl14bCvFF"
   },
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, input_size, output_size, stateful=False):\n",
    "        D,H = input_size, output_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        Wx = (rn(D,H*4) / np.sqrt(D)).astype('f') ######問2.2.1######\n",
    "        Wh = (rn(H,H*4) / np.sqrt(H)).astype('f') ######問2.2.2######\n",
    "        b = np.zeros(H*4).astype('f') ######問2.2.3######\n",
    "\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        self.input_shapes = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        self.input_shapes = [N,T,D]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:,t,:], self.h, self.c) ######問2.2.4######\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        H = Wh.shape[0]\n",
    "        N, T, D = self.input_shapes\n",
    "        \n",
    "        if dhs.ndim == 2:\n",
    "            temp = np.zeros((N,T,H))\n",
    "            temp[:,-1,:] = dhs\n",
    "            dhs = temp\n",
    "  \n",
    "        N, T, H = dhs.shape\n",
    " \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc) ######問2.2.5######\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2kB9QCjfqgM"
   },
   "source": [
    "### LSTMNetworkクラス\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UIwu6fuCvFI"
   },
   "outputs": [],
   "source": [
    "class LSTMNetwork:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(D, H, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofZZ-gIpCvFO"
   },
   "source": [
    "## 学習、評価\n",
    "\n",
    "ハイパーパラメータなどは先ほどのRNNと全て共通で学習させます。\n",
    "\n",
    "40エポックでperplexity が5以下となっていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcgBW6tmCvFP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | perplexity 278.48\n",
      "| epoch 2 | perplexity 224.88\n",
      "| epoch 3 | perplexity 205.25\n",
      "| epoch 4 | perplexity 188.97\n",
      "| epoch 5 | perplexity 175.05\n",
      "| epoch 6 | perplexity 155.77\n",
      "| epoch 7 | perplexity 133.43\n",
      "| epoch 8 | perplexity 106.73\n",
      "| epoch 9 | perplexity 81.01\n",
      "| epoch 10 | perplexity 58.26\n",
      "| epoch 11 | perplexity 40.60\n",
      "| epoch 12 | perplexity 27.62\n",
      "| epoch 13 | perplexity 20.00\n",
      "| epoch 14 | perplexity 14.09\n",
      "| epoch 15 | perplexity 10.32\n",
      "| epoch 16 | perplexity 7.90\n",
      "| epoch 17 | perplexity 5.75\n",
      "| epoch 18 | perplexity 4.58\n",
      "| epoch 19 | perplexity 3.62\n",
      "| epoch 20 | perplexity 3.06\n",
      "| epoch 21 | perplexity 2.63\n",
      "| epoch 22 | perplexity 2.23\n",
      "| epoch 23 | perplexity 1.98\n",
      "| epoch 24 | perplexity 1.73\n",
      "| epoch 25 | perplexity 1.67\n",
      "| epoch 26 | perplexity 1.53\n",
      "| epoch 27 | perplexity 1.43\n",
      "| epoch 28 | perplexity 1.36\n",
      "| epoch 29 | perplexity 1.30\n",
      "| epoch 30 | perplexity 1.28\n",
      "| epoch 31 | perplexity 1.27\n",
      "| epoch 32 | perplexity 1.21\n",
      "| epoch 33 | perplexity 1.20\n",
      "| epoch 34 | perplexity 1.18\n",
      "| epoch 35 | perplexity 1.17\n",
      "| epoch 36 | perplexity 1.11\n",
      "| epoch 37 | perplexity 1.11\n",
      "| epoch 38 | perplexity 1.07\n",
      "| epoch 39 | perplexity 1.04\n",
      "| epoch 40 | perplexity 1.02\n"
     ]
    }
   ],
   "source": [
    "model = LSTMNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "lstm_ppl_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    lstm_ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFCwUEpGfqgS"
   },
   "source": [
    "LSTMとRNNの学習結果を比較し、LSTMの方が安定して素早く学習が収束していることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJLiCyYQfqgS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(max_epoch), rnn_ppl_list)\n",
    "plt.plot(range(max_epoch), lstm_ppl_list)\n",
    "plt.legend([\"RNN\", \"LSTM\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0nOJV9OfqgV"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-lnDEQXfqgW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習成功です。次のステップに進んでください。\n"
     ]
    }
   ],
   "source": [
    "if rnn_ppl_list[-1] > 10:\n",
    "    print(\"RNNの実装に間違いがあります。問1を見直してください。\")\n",
    "elif lstm_ppl_list[-1] > 5:\n",
    "    print(\"LSTMの実装に間違いがあります。問2を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nYd6JNKfqgY"
   },
   "source": [
    "## GRU\n",
    "### GRUクラス\n",
    "\n",
    "問3-1. <font color=\"Red\">GRUクラスを完成させてください。</font>\n",
    "\n",
    "GRUクラスの仕様はLSTMクラスとほとんど同じです。\n",
    "\n",
    "各ゲートの計算と通常の順伝播の計算に使用するパラメータを行列にまとめ、一行で計算できるように実装しています。\n",
    "\n",
    "r がリセットゲート、zが更新ゲートを表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVTv0XjRfqgZ"
   },
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, Wx, Wh):\n",
    "        self.params = [Wx, Wh]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh = self.params\n",
    "        H, H3 = Wh.shape\n",
    "        Wxz, Wxr, Wx = Wx[:, :H], Wx[:, H:2 * H], Wx[:, 2 * H:]\n",
    "        Whz, Whr, Wh = Wh[:, :H], Wh[:, H:2 * H], Wh[:, 2 * H:]\n",
    "\n",
    "        z = sigmoid(np.dot(x, Wxz) + np.dot(h_prev, Whz))\n",
    "        r = sigmoid(np.dot(x, Wxr) + np.dot(h_prev, Whr))\n",
    "        h_hat = np.tanh(np.dot(x, Wx) + np.dot(r*h_prev, Wh))\n",
    "        h_next = (1-z) * h_prev + z * h_hat ######問3.1.1######\n",
    "\n",
    "        self.cache = (x, h_prev, z, r, h_hat)\n",
    "\n",
    "        return h_next\n",
    "\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh = self.params\n",
    "        H, H3 = Wh.shape\n",
    "        Wxz, Wxr, Wx = Wx[:, :H], Wx[:, H:2 * H], Wx[:, 2 * H:]\n",
    "        Whz, Whr, Wh = Wh[:, :H], Wh[:, H:2 * H], Wh[:, 2 * H:]\n",
    "        x, h_prev, z, r, h_hat = self.cache\n",
    "\n",
    "        dh_hat =dh_next * z\n",
    "        dh_prev = dh_next * (1-z)\n",
    "\n",
    "        dt = dh_hat * (1 - h_hat ** 2)\n",
    "        dWh = np.dot((r * h_prev).T, dt)\n",
    "        dhr = np.dot(dt, Wh.T)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "        dh_prev += r * dhr\n",
    "\n",
    "        dz = dh_next * h_hat - dh_next * h_prev\n",
    "        dt = dz * z * (1-z)\n",
    "        dWhz = np.dot(h_prev.T, dt)\n",
    "        dh_prev += np.dot(dt, Whz.T)\n",
    "        dWxz = np.dot(x.T, dt)\n",
    "        dx += np.dot(dt, Wxz.T)\n",
    "\n",
    "        dr = dhr * h_prev\n",
    "        dt = dr * r * (1-r)\n",
    "        dWhr = np.dot(h_prev.T, dt)\n",
    "        dh_prev += np.dot(dt, Whr.T)\n",
    "        dWxr = np.dot(x.T, dt)\n",
    "        dx += np.dot(dt, Wxr.T)\n",
    "\n",
    "        dWx = np.hstack((dWxz, dWxr, dWx))\n",
    "        dWh = np.hstack((dWhz, dWhr, dWh))\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "\n",
    "\n",
    "        return dx, dh_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xu6PRKnbfqgb"
   },
   "source": [
    "### TimeGRUクラス\n",
    "\n",
    "問3-2. <font color=\"Red\">TimeGRUクラスを完成させてください。</font>\n",
    "\n",
    "TimeGRUクラスの仕様はTimeLSTMクラスとほとんど同じです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x86i8uFrfqgb"
   },
   "outputs": [],
   "source": [
    "class TimeGRU:\n",
    "    def __init__(self, input_size, output_size, stateful=False):\n",
    "        D, H = input_size, output_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        Wx = (rn(D,H*3) / np.sqrt(D)).astype('f') ######問3.2.1######\n",
    "        Wh = (rn(H,H*3) / np.sqrt(H)).astype('f') ######問3.2.2######\n",
    "\n",
    "        self.params = [Wx, Wh]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh)]\n",
    "        self.layers = None\n",
    "        self.h = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H, H3 = Wh.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = GRU(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h) ######問3.2.3######\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        grads = [0,0]\n",
    "        dh = 0\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh) ######問3.2.4######\n",
    "\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "            \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFJXXrgGfqgd"
   },
   "source": [
    "### GRUNetworkクラス\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVUn_Ux7fqge"
   },
   "outputs": [],
   "source": [
    "class GRUNetwork:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeGRU(D, H, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjPajtgCfqgj"
   },
   "source": [
    "## 学習、評価\n",
    "\n",
    "ハイパーパラメータなどは先ほどのRNN・LSTMと全て共通で学習させます。\n",
    "\n",
    "40エポックでperplexity が5以下となっていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AAxu72Ofqgk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | perplexity 288.44\n",
      "| epoch 2 | perplexity 204.04\n",
      "| epoch 3 | perplexity 170.58\n",
      "| epoch 4 | perplexity 121.40\n",
      "| epoch 5 | perplexity 77.48\n",
      "| epoch 6 | perplexity 47.27\n",
      "| epoch 7 | perplexity 31.21\n",
      "| epoch 8 | perplexity 20.84\n",
      "| epoch 9 | perplexity 13.75\n",
      "| epoch 10 | perplexity 9.34\n",
      "| epoch 11 | perplexity 6.24\n",
      "| epoch 12 | perplexity 4.44\n",
      "| epoch 13 | perplexity 3.38\n",
      "| epoch 14 | perplexity 2.62\n",
      "| epoch 15 | perplexity 2.13\n",
      "| epoch 16 | perplexity 1.75\n",
      "| epoch 17 | perplexity 1.58\n",
      "| epoch 18 | perplexity 1.44\n",
      "| epoch 19 | perplexity 1.35\n",
      "| epoch 20 | perplexity 1.31\n",
      "| epoch 21 | perplexity 1.25\n",
      "| epoch 22 | perplexity 1.20\n",
      "| epoch 23 | perplexity 1.19\n",
      "| epoch 24 | perplexity 1.14\n",
      "| epoch 25 | perplexity 1.13\n",
      "| epoch 26 | perplexity 1.11\n",
      "| epoch 27 | perplexity 1.11\n",
      "| epoch 28 | perplexity 1.06\n",
      "| epoch 29 | perplexity 1.06\n",
      "| epoch 30 | perplexity 1.05\n",
      "| epoch 31 | perplexity 1.05\n",
      "| epoch 32 | perplexity 1.03\n",
      "| epoch 33 | perplexity 1.02\n",
      "| epoch 34 | perplexity 1.01\n",
      "| epoch 35 | perplexity 1.01\n",
      "| epoch 36 | perplexity 1.01\n",
      "| epoch 37 | perplexity 1.01\n",
      "| epoch 38 | perplexity 1.01\n",
      "| epoch 39 | perplexity 1.01\n",
      "| epoch 40 | perplexity 1.01\n"
     ]
    }
   ],
   "source": [
    "model = GRUNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "gru_ppl_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    gru_ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqlkZ1rDfqgn"
   },
   "source": [
    "GRUとLSTM、RNNの学習結果を比較し、GRUがLSTMと同様（若しくはそれ以上）の性能を持っていることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMrlOBMYfqgo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(max_epoch), rnn_ppl_list)\n",
    "plt.plot(range(max_epoch), lstm_ppl_list)\n",
    "plt.plot(range(max_epoch), gru_ppl_list)\n",
    "plt.legend([\"RNN\", \"LSTM\", \"GRU\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFoAaZPGfqgq"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOSgH6OFfqgq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習成功です。次のステップに進んでください。\n"
     ]
    }
   ],
   "source": [
    "if gru_ppl_list[-1] > 5:\n",
    "    print(\"GRUの実装に間違いがあります。問3を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqdA7XJPfqgs"
   },
   "source": [
    "## Classification\n",
    "では実際にRNNやLSTMを用いて実践的な問題を解いていきましょう。\n",
    "\n",
    "今回解いていくタスクは二値分類なので、まずは出力層の活性化と損失関数をつなげたSigmoidWithLossクラスを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrHIiCb1fqgt"
   },
   "outputs": [],
   "source": [
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        x = x.flatten()\n",
    "        self.y = sigmoid(x)\n",
    "        self.loss = -np.mean(np.log(self.y + 1e-7) * t + np.log(1 - self.y + 1e-7) * (1 - t))\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t)/batch_size\n",
    "        dx = dx.reshape(-1,1)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VlQBlByfqgu"
   },
   "source": [
    "## データセットの用意\n",
    "\n",
    "今回使用するデータは \"movie review\" と呼ばれる映画の評論記事の分類問題です。\n",
    "評論記事に対して「1(positive)」「0(negative)」の二値がラベルとして付与されています。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "pip install --user gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pqqq2d7fqgu"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYaC0Zar0VIG"
   },
   "outputs": [],
   "source": [
    "def load_movie_reviews():\n",
    "    from nltk.corpus import movie_reviews\n",
    "    try:\n",
    "        movie_reviews.categories()\n",
    "    except:\n",
    "        import nltk\n",
    "        nltk.download('movie_reviews')\n",
    "        from nltk.corpus import movie_reviews\n",
    "    raw_data = []\n",
    "\n",
    "    # NLTK's corpus is structured in an interesting way\n",
    "    # first iterate through the two categories (pos and neg)\n",
    "    for category in movie_reviews.categories():\n",
    "\n",
    "        if category == 'pos':\n",
    "            label = '1'\n",
    "        elif category == 'neg':\n",
    "            label = '0'\n",
    "\n",
    "        # each of these categories is just fileids, so grab those\n",
    "        for fileid in movie_reviews.fileids(category):\n",
    "            # then each review is a NLTK class where each item in that class instance is a word\n",
    "            review_words = list(movie_reviews.words(fileid))\n",
    "            if len(review_words) >= 400:\n",
    "                review_words = review_words[:400]\n",
    "            else:\n",
    "                review_words.extend([\" \" for i in range(400 - len(review_words))])\n",
    "            review_dictionary = {\n",
    "                'text': review_words,\n",
    "                'label': label\n",
    "            }\n",
    "\n",
    "            raw_data.append(review_dictionary)\n",
    "\n",
    "    return raw_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6v2fr-ifqg0"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"data.pkl\"):\n",
    "    f = open(\"data.pkl\", \"rb\")\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    data = load_movie_reviews()\n",
    "    f = open(\"data.pkl\", \"wb\")\n",
    "    pickle.dump(data,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8N0RpQ9fqg2"
   },
   "source": [
    "## Embedder の用意\n",
    "\n",
    "先ほどの例ではEmbed層をネットワーク内に含めていましたが、Embed 層も含めて学習をすると時間がかかってしまうため、今回はあらかじめ用意された embedder を使用してネットワークに入れる前に単語列をベクトル化しておきます。\n",
    "\n",
    "embedderモデルのダウンロードには時間がかかりますのでご注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMreDRKVfqg4"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"embedder.model\"):\n",
    "    model = word2vec.Word2VecKeyedVectors.load_word2vec_format(\"embedder.model\")\n",
    "else:\n",
    "    model = api.load(\"glove-twitter-25\")\n",
    "    model.save_word2vec_format(\"embedder.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyYQCUWhfqg5"
   },
   "outputs": [],
   "source": [
    "def embed_one_word_via_model(word, model):\n",
    "    try:\n",
    "        return model[word]\n",
    "    except:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kM0P0RPCfqg6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding = []\n",
    "labels = []\n",
    "for d in data:\n",
    "    embedding.append(np.array([embed_one_word_via_model(word,model) for word in d[\"text\"]]))\n",
    "    labels.append(int(d[\"label\"]))\n",
    "embedding = np.array(embedding)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, T_train, T_test = train_test_split(embedding, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXAGW9TIfqg8"
   },
   "source": [
    "## ネットワーク の用意\n",
    "問4-1. <font color=\"Red\">以下の SimpleRNNClassifier, LSTMClassifier クラスを完成させてください。</font>\n",
    "\n",
    "先ほどの問題では各時刻の入力に対して一つずつ出力が計算されましたが、今回のタスクにおいては、全時刻の入力データに対して一つの出力を計算します。\n",
    "\n",
    "そのため、順伝播においてRNN層やLSTM層の出力に対して、時系列のうち最終出力のみを取り出し、Affine層に入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIDbWI_Vfqg8"
   },
   "outputs": [],
   "source": [
    "class SimpleRNNClassifier:\n",
    "    def __init__(self, wordvec_size, hidden_size):\n",
    "        D, H = wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, 1) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.affine_layer = Affine(affine_W, affine_b)\n",
    "        self.loss_layer = SigmoidWithLoss()\n",
    "        self.rnn_layer = TimeRNN(D, H, stateful=False)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += self.rnn_layer.params\n",
    "        self.grads += self.rnn_layer.grads\n",
    "        self.params += self.affine_layer.params\n",
    "        self.grads += self.affine_layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        xs = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        xs = self.rnn_layer.forward(xs)[:, -1, :] ######問4.1.1######\n",
    "        xs = self.affine_layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        dout = self.affine_layer.backward(dout)\n",
    "        dout = self.rnn_layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA1SBFVGfqg-"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier:\n",
    "    def __init__(self, wordvec_size, hidden_size):\n",
    "        D, H = wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        rnn_Wx = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(4*H).astype('f')\n",
    "        affine_W = (rn(H, 1) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.affine_layer = Affine(affine_W, affine_b)\n",
    "        self.loss_layer = SigmoidWithLoss()\n",
    "        self.rnn_layer = TimeLSTM(D, H, stateful=False)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += self.rnn_layer.params\n",
    "        self.grads += self.rnn_layer.grads\n",
    "        self.params += self.affine_layer.params\n",
    "        self.grads += self.affine_layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        xs = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        xs = self.rnn_layer.forward(xs)[:, -1, :] ######問4.1.2###### \n",
    "        xs = self.affine_layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        dout = self.affine_layer.backward(dout)\n",
    "        dout = self.rnn_layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MF8LrN-5fqhA"
   },
   "source": [
    "## 学習の実行\n",
    "今回のタスクにおいては、RNNではうまく学習が行われず損失があまり減少してくれません。\n",
    "\n",
    "対してLSTMでは順調に損失が減少します。\n",
    "\n",
    "学習の実行には少々時間がかかるため、注意してください。\n",
    "\n",
    "10エポックでLSTMの損失が0.5を下回っていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUwoisD8fqhB"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 10\n",
    "eval_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYnwApPQfqhC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| idx 0 / 1500 | RNN loss 0.71 | LSTM loss 0.71 |\n",
      "| idx 500 / 1500 | RNN loss 0.82 | LSTM loss 0.72 |\n",
      "| idx 1000 / 1500 | RNN loss 0.78 | LSTM loss 0.71 |\n",
      "| epoch 1 | RNN loss 0.77 | LSTM loss 0.71 | RNN accuracy 50.60 | LSTM accuracy 50.80\n",
      "| idx 0 / 1500 | RNN loss 0.71 | LSTM loss 0.70 |\n",
      "| idx 500 / 1500 | RNN loss 0.68 | LSTM loss 0.68 |\n",
      "| idx 1000 / 1500 | RNN loss 0.69 | LSTM loss 0.68 |\n",
      "| epoch 2 | RNN loss 0.69 | LSTM loss 0.68 | RNN accuracy 49.60 | LSTM accuracy 52.00\n",
      "| idx 0 / 1500 | RNN loss 0.63 | LSTM loss 0.66 |\n",
      "| idx 500 / 1500 | RNN loss 0.66 | LSTM loss 0.68 |\n",
      "| idx 1000 / 1500 | RNN loss 0.66 | LSTM loss 0.67 |\n",
      "| epoch 3 | RNN loss 0.66 | LSTM loss 0.66 | RNN accuracy 51.20 | LSTM accuracy 52.20\n",
      "| idx 0 / 1500 | RNN loss 0.67 | LSTM loss 0.66 |\n",
      "| idx 500 / 1500 | RNN loss 0.62 | LSTM loss 0.63 |\n",
      "| idx 1000 / 1500 | RNN loss 0.63 | LSTM loss 0.63 |\n",
      "| epoch 4 | RNN loss 0.63 | LSTM loss 0.63 | RNN accuracy 53.60 | LSTM accuracy 53.40\n",
      "| idx 0 / 1500 | RNN loss 0.60 | LSTM loss 0.63 |\n",
      "| idx 500 / 1500 | RNN loss 0.61 | LSTM loss 0.58 |\n",
      "| idx 1000 / 1500 | RNN loss 0.60 | LSTM loss 0.58 |\n",
      "| epoch 5 | RNN loss 0.60 | LSTM loss 0.57 | RNN accuracy 54.00 | LSTM accuracy 50.60\n",
      "| idx 0 / 1500 | RNN loss 0.49 | LSTM loss 0.47 |\n",
      "| idx 500 / 1500 | RNN loss 0.54 | LSTM loss 0.53 |\n",
      "| idx 1000 / 1500 | RNN loss 0.56 | LSTM loss 0.51 |\n",
      "| epoch 6 | RNN loss 0.57 | LSTM loss 0.52 | RNN accuracy 51.40 | LSTM accuracy 51.40\n",
      "| idx 0 / 1500 | RNN loss 0.57 | LSTM loss 0.59 |\n",
      "| idx 500 / 1500 | RNN loss 0.56 | LSTM loss 0.53 |\n",
      "| idx 1000 / 1500 | RNN loss 0.57 | LSTM loss 0.52 |\n",
      "| epoch 7 | RNN loss 0.58 | LSTM loss 0.52 | RNN accuracy 53.00 | LSTM accuracy 51.40\n",
      "| idx 0 / 1500 | RNN loss 0.62 | LSTM loss 0.53 |\n",
      "| idx 500 / 1500 | RNN loss 0.67 | LSTM loss 0.46 |\n",
      "| idx 1000 / 1500 | RNN loss 0.70 | LSTM loss 0.46 |\n",
      "| epoch 8 | RNN loss 0.72 | LSTM loss 0.45 | RNN accuracy 51.60 | LSTM accuracy 54.00\n",
      "| idx 0 / 1500 | RNN loss 0.71 | LSTM loss 0.37 |\n",
      "| idx 500 / 1500 | RNN loss 0.71 | LSTM loss 0.39 |\n",
      "| idx 1000 / 1500 | RNN loss 0.71 | LSTM loss 0.37 |\n",
      "| epoch 9 | RNN loss 0.71 | LSTM loss 0.36 | RNN accuracy 50.00 | LSTM accuracy 47.80\n",
      "| idx 0 / 1500 | RNN loss 0.68 | LSTM loss 0.31 |\n",
      "| idx 500 / 1500 | RNN loss 0.69 | LSTM loss 0.26 |\n",
      "| idx 1000 / 1500 | RNN loss 0.70 | LSTM loss 0.25 |\n",
      "| epoch 10 | RNN loss 0.70 | LSTM loss 0.24 | RNN accuracy 48.80 | LSTM accuracy 50.60\n"
     ]
    }
   ],
   "source": [
    "rnn_model = SimpleRNNClassifier(25, 100)\n",
    "lstm_model = LSTMClassifier(25, 100)\n",
    "optimizer1 = Adam(lr)\n",
    "optimizer2 = Adam(lr)\n",
    "batch_size = 100\n",
    "rnn_loss_list = []\n",
    "lstm_loss_list = []\n",
    "\n",
    "np.random.seed(0)\n",
    "for epoch in range(n_epoch):\n",
    "    total_rnn_loss = 0\n",
    "    total_lstm_loss = 0\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    for i, idx in enumerate(range(0, len(X_train), batch_size)):\n",
    "        X_batch = X_train[perm[idx:idx+batch_size]]\n",
    "        T_batch = T_train[perm[idx:idx+batch_size]]\n",
    "        \n",
    "        rnn_loss = rnn_model.forward(X_batch, T_batch)\n",
    "        rnn_model.backward()\n",
    "        optimizer1.update(rnn_model.params, rnn_model.grads)\n",
    "        total_rnn_loss += rnn_loss*len(X_batch)\n",
    "        \n",
    "        lstm_loss = lstm_model.forward(X_batch, T_batch)\n",
    "        lstm_model.backward()\n",
    "        optimizer2.update(lstm_model.params, lstm_model.grads)\n",
    "        total_lstm_loss += lstm_loss*len(X_batch)\n",
    "        if i % eval_interval == 0:\n",
    "            print('| idx %d / %d | RNN loss %.2f | LSTM loss %.2f |'\n",
    "                 %(idx, len(X_train), total_rnn_loss/(idx+batch_size), total_lstm_loss/(idx+batch_size)))\n",
    "    average_rnn_loss = total_rnn_loss / len(X_train)\n",
    "    rnn_loss_list.append(average_rnn_loss)\n",
    "    average_lstm_loss = total_lstm_loss / len(X_train)\n",
    "    lstm_loss_list.append(average_lstm_loss)\n",
    "    rnn_pred = rnn_model.predict(X_test).flatten()\n",
    "    lstm_pred = lstm_model.predict(X_test).flatten()\n",
    "    rnn_accuracy = ((rnn_pred > 0) == T_test).mean() * 100\n",
    "    lstm_accuracy = ((lstm_pred > 0) == T_test).mean() * 100\n",
    "    print('| epoch %d | RNN loss %.2f | LSTM loss %.2f | RNN accuracy %.2f | LSTM accuracy %.2f'\n",
    "          % (epoch+1, average_rnn_loss, average_lstm_loss, rnn_accuracy, lstm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Tz2CZSMfqhE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(n_epoch), rnn_loss_list)\n",
    "plt.plot(range(n_epoch), lstm_loss_list)\n",
    "plt.legend([\"RNN\", \"LSTM\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIVdkC18fqhF"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lsEHccrfqhG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習成功です。次のステップに進んでください。\n"
     ]
    }
   ],
   "source": [
    "if average_lstm_loss > 0.5:\n",
    "    print(\"RNN、LSTMの実装に間違いがあります。問4-1を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pim2OwvSfqhH"
   },
   "source": [
    "## bi-directional LSTM\n",
    "問4-2. <font color=\"Red\">以下の BidirectionalLSTMClassifier クラスを完成させてください。</font>\n",
    "\n",
    "入力系列データに対して、順方向のデータを処理するforward LSTM層と逆方向のデータを処理するbackward LSTM層を用意します。\n",
    "\n",
    "通常のLSTM層とパラメータ数が大きく変わらないように各LSTM層は hidden_size の半分の次元数を出力します。\n",
    "\n",
    "forward LSTM と backward LSTM の出力を横につなげ、affine層に入力し分類タスクを解きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-WuCyNQfqhH"
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTMClassifier:\n",
    "    def __init__(self, wordvec_size, hidden_size):\n",
    "        D, H = wordvec_size, hidden_size //2\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        affine_W = (rn(H * 2, 1) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.affine_layer = Affine(affine_W, affine_b)\n",
    "        self.loss_layer = SigmoidWithLoss()\n",
    "        self.forward_rnn_layer = TimeLSTM(D, H, stateful=False)\n",
    "        self.backward_rnn_layer = TimeLSTM(D, H, stateful=False)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += self.forward_rnn_layer.params\n",
    "        self.grads += self.forward_rnn_layer.grads\n",
    "        self.params += self.backward_rnn_layer.params\n",
    "        self.grads += self.backward_rnn_layer.grads\n",
    "        self.params += self.affine_layer.params\n",
    "        self.grads += self.affine_layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        xs = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        forward_xs = self.forward_rnn_layer.forward(xs)[:, -1, :] ######問4.2.1######\n",
    "        backward_xs = self.backward_rnn_layer.forward(xs[:,::-1,:])[:, -1, :] ######問4.2.2######[######問4.2.3######] \n",
    "        xs = np.hstack((forward_xs, backward_xs))\n",
    "        xs = self.affine_layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        dout = self.affine_layer.backward(dout)\n",
    "        dout1, dout2 = np.hsplit(dout, 2)\n",
    "        dout1 = self.forward_rnn_layer.backward(dout1)\n",
    "        dout2 = self.backward_rnn_layer.backward(dout2)\n",
    "        return (dout1, dout2)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.forward_rnn_layer.reset_state()\n",
    "        self.backward_rnn_layer.reset_state()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zi_LUaBfqhJ"
   },
   "source": [
    "## 学習の実行\n",
    "Bidirectional LSTM がLSTMより良い性能を出していることを確認してください。\n",
    "\n",
    "10エポックで損失が0.2を下回っていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IA0CXrw7fqhJ"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 10\n",
    "eval_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SatWLZ07fqhL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| idx 0 / 1500 | BiLSTM loss 0.72 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.71 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.71 |\n",
      "| epoch 1 | BiLSTM loss 0.70 | BiLSTM accuracy 50.40\n",
      "| idx 0 / 1500 | BiLSTM loss 0.69 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.67 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.67 |\n",
      "| epoch 2 | BiLSTM loss 0.67 | BiLSTM accuracy 53.00\n",
      "| idx 0 / 1500 | BiLSTM loss 0.63 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.65 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.65 |\n",
      "| epoch 3 | BiLSTM loss 0.64 | BiLSTM accuracy 53.40\n",
      "| idx 0 / 1500 | BiLSTM loss 0.60 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.60 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.59 |\n",
      "| epoch 4 | BiLSTM loss 0.59 | BiLSTM accuracy 49.20\n",
      "| idx 0 / 1500 | BiLSTM loss 0.57 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.52 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.52 |\n",
      "| epoch 5 | BiLSTM loss 0.52 | BiLSTM accuracy 51.40\n",
      "| idx 0 / 1500 | BiLSTM loss 0.47 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.44 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.41 |\n",
      "| epoch 6 | BiLSTM loss 0.42 | BiLSTM accuracy 53.60\n",
      "| idx 0 / 1500 | BiLSTM loss 0.32 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.29 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.30 |\n",
      "| epoch 7 | BiLSTM loss 0.30 | BiLSTM accuracy 54.40\n",
      "| idx 0 / 1500 | BiLSTM loss 0.21 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.20 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.19 |\n",
      "| epoch 8 | BiLSTM loss 0.19 | BiLSTM accuracy 51.00\n",
      "| idx 0 / 1500 | BiLSTM loss 0.10 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.13 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.12 |\n",
      "| epoch 9 | BiLSTM loss 0.12 | BiLSTM accuracy 52.40\n",
      "| idx 0 / 1500 | BiLSTM loss 0.12 |\n",
      "| idx 500 / 1500 | BiLSTM loss 0.10 |\n",
      "| idx 1000 / 1500 | BiLSTM loss 0.12 |\n",
      "| epoch 10 | BiLSTM loss 0.12 | BiLSTM accuracy 51.20\n"
     ]
    }
   ],
   "source": [
    "bilstm_model = BidirectionalLSTMClassifier(25, 100)\n",
    "optimizer = Adam(lr)\n",
    "batch_size = 100\n",
    "bilstm_loss_list = []\n",
    "np.random.seed(0)\n",
    "for epoch in range(n_epoch):\n",
    "    total_bilstm_loss = 0\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    for i, idx in enumerate(range(0, len(X_train), batch_size)):\n",
    "        X_batch = X_train[perm[idx:idx+batch_size]]\n",
    "        T_batch = T_train[perm[idx:idx+batch_size]]\n",
    "        \n",
    "        bilstm_loss = bilstm_model.forward(X_batch, T_batch)\n",
    "        bilstm_model.backward()\n",
    "        optimizer.update(bilstm_model.params, bilstm_model.grads)\n",
    "        total_bilstm_loss += bilstm_loss*len(X_batch)\n",
    "        if i % eval_interval == 0:\n",
    "            print('| idx %d / %d | BiLSTM loss %.2f |'\n",
    "                 %(idx, len(X_train), total_bilstm_loss/(idx+batch_size)))\n",
    "\n",
    "    average_bilstm_loss = total_bilstm_loss / len(X_train)\n",
    "    bilstm_loss_list.append(average_bilstm_loss)\n",
    "    bilstm_pred = bilstm_model.predict(X_test).flatten()\n",
    "    bilstm_accuracy = ((bilstm_pred > 0) == T_test).mean() * 100\n",
    "    print('| epoch %d | BiLSTM loss %.2f | BiLSTM accuracy %.2f'\n",
    "          % (epoch+1, average_bilstm_loss, bilstm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPIvmRBofqhM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4VEX3wPHvZLPpBdIoCSSUUAKBAJESirRQLCAWFEUUVFTAgr4KlvcFsSsWUPghIk0U7AhKlWKhKC1SQi+hlyRAQgopO78/NsSAkCywm5tNzud59sneu7ccEPdk7sycUVprhBBCCAAXowMQQghRdkhSEEIIUUiSghBCiEKSFIQQQhSSpCCEEKKQJAUhhBCFHJoUlFI9lFI7lVJ7lFIjL/N5TaXUCqXUJqXUZqXUTY6MRwghRPGUo+YpKKVMwC4gHjgMrAP6aa0TixwzGdiktf4/pVQUsEBrHeGQgIQQQpTIkS2FlsAerfU+rXUOMAfofckxGvAreO8PHHVgPEIIIUrg6sBrhwKHimwfBlpdcsxoYIlS6gnAG+jqwHiEEEKUwJFJwRb9gOla6/eUUm2Az5VSjbXWlqIHKaUGA4MBvL29WzRo0MCAUIUQwnlt2LAhWWsdXNJxjkwKR4AaRbbDCvYV9RDQA0BrvUYp5QEEASeLHqS1ngxMBoiNjdXr1693VMxCCFEuKaWSbDnOkX0K64BIpVQtpZQbcA8w75JjDgJdAJRSDQEP4JQDYxJCCFEMhyUFrXUeMAxYDGwHvtZab1NKjVFK9So47FngEaXU38Bs4EEtZVuFEMIwDu1T0FovABZcsu9/Rd4nAm0dGYMQQgjbyYxmIYQQhSQpCCGEKCRJQQghRCFJCkIIIQpVmKSw79Q53l28g5w8S8kHCyFEBVVhksLSxBNMWLGXO/5vNftOnTM6HCGEKJMqTFJ49MY6TOrfgkOnM7nloz/4et0hZEqEEEJcrMIkBYAejauy8Kn2NA2rxPPfbWbY7E2czcw1OiwhhCgzKlRSAKjm78msh1vxfI/6LN56nJ7jfuOv/alGhyWEEGVChUsKACYXxZCOdfnu8TjcXF24Z/Ia3l+yk7x86YQWQlRsFTIpXNC0RiV+erI9tzcPY/zyPfT9ZA2HUjONDksIIQxToZMCgI+7K2Pvasr4fs3YffIcPcf9zo8Jl1b4FkKIiqHCJ4ULejWtzoIn29Ogqi9PzUlg+FcJpGdLJ7QQomKRpFBEjQAv5gxuzdNdI/kx4Qg3jf+djQdPGx2WEEKUGkkKl3A1ufB013p8/WgbLBa4a9IaPl6+m3yLzGkQQpR/khSuIDYigIVPt+em6GqMXbKLfp+u5eiZLKPDEkIIh5KkUAw/DzPj74nhvbuasu3IWXp8+BsLthwzOiwhhHAYSQolUEpxR4swFjzVnlrBPgz5YiMjvt1Mxvk8o0MTQgi7c+hynOVJeKA33z7Whg9/2cXElXtZdyCVcfc0IzrM3+jQhCiXNiSlsnpPCpW8zFTycqOSl5nKBT8rebnh7WZCKWV0mOWOcraicLGxsXr9+vWGxrBmbwrDv0ogJeM8/+lWn0fa18bFRf5xCmEvWw6f5c5JqzlfTKl7N5ML/l5mKnuZqeT576RR+ZJkUtnLjL+XGXdXUyn+ScoOpdQGrXVsicdJUrg2ZzJzGPndFhZtO07buoG83zeGKn4eRoclhNNLPneeXh/9gVKK7x6Pw+SiOJOZw+nMXM5k5nAmM5fTBdtns3I4nWHdPpOZy5ks6/7i1k3xcjMVSR5FEkiRxFLZ24y/p3V/ZS83/DzNmJz8Fz9JCqVAa81X6w7xyvxEPMwuvHNnU+KjqhgdlhBOKzffwn1T/uTvQ2f47vE4Gode/eNZrTVZufmFyaPozwvJ5XRmDmcv+fxsVi5XGnmuFFTyNFPZ262g1eFGgPc/2wFebgXvrfsCymAisTUpOLRPQSnVAxgHmIApWuu3Lvn8A6BTwaYXEKK1ruSQYM6dhPPpEFDb+l/YDpRS3NOyJrERATw1ZxOPzFzP/a3DeenmhniYK2YTVYjr8dpPify1P5UP7465poQA1v8vvdxc8XJzpXolT5vPs1g06dl51kSRdSFhWFsiZzJzSL2QUDJyOHw6k61HcknNyCHnCoU0iyaSAC83KtmQSPw9zYY/inZYUlBKmYAJQDxwGFinlJqntU68cIzWeniR458AmjkqHhK+hF9GgU8VqNkGwuOsr5AocLm+L/C6IT58PySOsYt38unv+1m7L4Xx/ZrRsJqfnYIXovz7et0hZqxJ4pH2tbitWWip39/FReFf0O9gK601mTn51sdZGbnWxJGRU7B99YnERYF/MYnkxnrBDv9ecWRLoSWwR2u9D0ApNQfoDSRe4fh+wChHBbOkcjBzGsXRLd9M16MbCEqca/3A3R9qtobwNhDeFqrFgKvbVV/f3dXESzdH0aFeMM98/Te9J6zihZ4NeDAuQkZICFGCTQdP8/LcrbSrG8SIHg2MDsdmSim83V3xdnclrLJt51xIJKkZ1kdXJSWSLUesCScn34K/p9mpk0IocKjI9mGg1eUOVEqFA7WA5Y4KxuIdSKrZndcz9/JGZRea172JeI9Q4jPOEXJoA+xebD3Q1RPCYv9pSYTdAG7eNt+nfWQwi55qz/PfbuaV+Yn8tusU797VlCAfdwf9yYRwbifTsnls1gaq+LvzUb9muJrK9/SpoomkRoBt51xIJKXRR+Gwjmal1J1AD631wwXb9wOttNbDLnPsCCBMa/3EFa41GBgMULNmzRZJSUnXHNfeM3tZkrSEJQeWsOfMHgCahTQjvmob4vGm6ontkLQKjm8BbQEXV6jW1JogasZZWxVeJf+X1Frz+dokXvt5O34eZsbe1YSO9UOuOW4hyqPzefn0m7yW7cfS+X5InDxydSDDRx8ppdoAo7XW3Qu2XwDQWr95mWM3AUO11qtLuq49Rx/tO7uPpQeWsjRpKTtP7wSgSXATuoV3I75qG6qnHoSDqyFpNRzZAPk51hNDogqSREHfhF/1K95j5/F0npy9iZ0n0hnUthYjetavsOOkhbjUC99vYfZfB5l4X3Nuiq5mdDjlWllICq7ALqALcARYB9yrtd52yXENgEVALW1DMI4aknrg7AF+OfgLSw4sYXvqdgCig6KJD48nPjyeMI8gOLrR2opIWgOH/oScc9aTK0dY+yMuJIlLRjhl5+bz1sIdTF99gIbV/Hjz9miiQ/3L1HA1IUrbrLVJvDx3K0M71eG57s7Tj+CsDE8KBUHcBHyIdUjqVK3160qpMcB6rfW8gmNGAx5a65G2XLM05ikcSjvE0oNLWXJgCdtSrDksKjCKbuHd6BbejRp+NSA/D05ssbYiklbDwTWQmWK9QOEIp7bWDuyQRuDiwvIdJ/jPN5tJzcjB02yiUXU/Gof6Ex3qT3SYP3WCfSRRiArhr/2p3PvpWtpHBjHlgRvk330pKBNJwRFKe/LakXNHWHpgKUuSlrAleQsADQIaWB8xhccT4R9hPVBrSN71T5JIWg1ph62fefhDDesIp7MhN7DsbHU2H8ti65GzbDuaRlZuPgCeZhNR1f2IDvWncag/TSRRiHLo2Nksbv3oD3w9zMwd2hZ/T9uHgIprJ0nBAY6eO8rSJGsfxN+n/gagXuV6xIfH0y2iG7X9a198wpmD1kdNSausLYnkXdb9ygSVwyEwEktAHU6512RHbhXWpwew5qSZbcfSr5gookP9qRPsXe5HaIjyKTs3n76frGHfqQzmDo2jboiv0SFVGJIUHOx4xnF+SfqFpUlL2XRyExpN3Up1C1sQdSvX/fdJ505Zk8PxzZC8G1L2QsoeyCuyeI+bDzqwDue8IzjsEkpibgh/pgWy/JQvyTnW+RMeZheiqvkVPHaqJIlCOAWtNf/5ZjPfbTzM5Ptb0K1RVaNDqlAkKZSik5kn+SXpF5YkLWHjiY1oNLX9axe2ICIrRV55ApvFAmlHrMnhwit5N6TshjOHgH/+++R5V+G0R02SVCjbzgez5mwA23OrcFgHYzabCxNF44I+irrBPpIoRJkxbdV+XpmfyNNdI3m6az2jw6lwJCkYJDkrubAFsf7EeizaQoRfRGGCqF+5vu0znHOzIXVfQbLYDcl7/nmfdbrwMItyJcU9lAO6Gluyg9mZV5V9lmocda1Olao1iA6rJIlCGGr13mTu/+wvOjcI4ZP+LQyv71MRSVIoA5Kzkll+cDlLkpaw7vg6LNpCTd+adAjrQOOgxkQFRhHuF46LuoYv6czUghbFhYRhfRylU/eiLsynADKUN3st1dhjsSaKw6bqqMBIAmo2pEmtarSPDCbA++rLeghhq0OpmfT6+A8Cfdz5YUgcvh7SsWwESQplTGp2qjVBHFjCxpMbOZ9/HgBvszcNAxoSFRhFo8BGRAVGUdOv5rUlCgBLPpw9dFGrQifvJu/Ubsznjl506E5LGCstMRwIbEdQg/a0q1+NZjUr4+YqLQlhH1k5+dzxf6s5dDqTH4e2pXawj9EhVViSFMqwPEsee8/sJTElkW0p29iesp2dp3cWJgofsw8NAxsSFRBlTRZBjajhW+PaE8UFORnWx1HJu7Gc2kXGrl/xOv4XJp1HuvbkN0s0q1VzssM70zSqPh0ig4kIsr3ukxBFaa15ak4C8zcfZeqDN9BJyrwYSpKCk8m15LLvzL7CRJGYksjO1J3kWKyPgnzMPkQFRhW+GgVaE8V1V2DNToP9v5KzYxGWnUvwyD4JwBZLBCssMWz3bk1g/Ta0q1eVuLqB+EnTX9ho8m97eWPBDp7vUZ8hHS8zGk+UKkkK5UCuJbewRZGYksi25G3sOr2rMFH4mn1pGNiw8LFTVGDU9SUKreHEVti9hOzERbgdW48LFk5rX1ZamvCrbsaZau1p3qAO7SODaBJWSSbWicv6ddcpBk77i56Nq/Hxvc2kfHwZIEmhnLqQKLYlbytsVew6vYtcSy4Avm6+1sdOQQUtioBGhPmGXdv/lJmpsG8Flp2Lyd+1FPP5VPJxIcFShxX5Max3iyWobizt64XQPjL4qla5EuXXgeQMen38B9UrefL9kDi83By6wKOwkSSFCiQ3P5c9Z/YUPnZKTEm8KFH4uflZ+yiKdGaH+VxlorBY4Ogm2L2EvJ2LcT2+CYBkKrE8rykrLDEcDWxNi3oRtK8XROtagXi6STXYiibjfB59Jq7iZPp55g1tR81AL6NDEgUkKVRwufm57D6z+1+JIs+SB1gTRYewDjzY6EHqB9S/+hucOwl7lqF3L8GyexmmnLPkYWKDpT7L8pvyB82pHBFNh4JWRMNqvvIIoZzTWvP4rI0sSTzOzEGtaBcZZHRIoghJCuJfcvJz2H1mN4kpiWw5tYXFBxaTmZdJ29C2PNT4IWKrxF7bF3d+HhxeB7uXYNm1BJeTWwE4oYJZmtuEFZYYdnk154Z6YXSIDKZdZJCsRFcOfbx8N2OX7OLlmxvycPvaJZ8gSpUkBVGis+fP8tXOr/hi+xekZqcSHRTNoMaD6FSjEyaX63j0c/YI7PnFmiT2rsAlN4M8ZWadjmJJbhOWW5rhU60eHeoF0z4yiNjwAJkb4eSWbT/BwzPX07tpdT64O0ZahWWQJAVhs+y8bObtncf0bdM5lH6ICL8IHmj0AL3q9MLNdJ2znfPOW4sA7l6K3r0EVVAp9qgplMU50SzPj2GLuQltIqvSqUEIneqHEOwrrQhnsvfUOW77eBXhQV58+1gcHmbpSyqLJCmIq5ZvyWfpwaVM3TKV7anbCfIMon/D/vSt3xdfNzuVOE7dX9iK0Pt/Q+Vlk+wWxgf5d/NlRjM0LjQJ86dzgxA6NwihcXV/qZNThqVl53LbhFWczcxl3hPtCJURaGWWJAVxzbTWrD22lmlbp7Hm2Bq8zd70rdeX/lH9CfGy46zU3CzYvQRWvgUnE8kKimZJtUeZcaI2mw6dQWsI9nWnY71gujQMoV1kMD7uMryxrLBYNIM/X8/Knaf44uFWtKodaHRIohiSFIRdJKYkMm3rNJYkLcGkTNxa51YebPQgtfxr2e8mlnzY8g0sfx3OHoRaN3Km7UssTwtl+Y6T/LbrFGnZeZhNipa1AujcoAqdG4RQS0pwGOr9pbsYv2w3Y3o3YkCbCKPDESWQpCDs6lDaIWYkzmDunrnk5OfQuWZnBjUeRJPgJva7Sd55WD8VfnvXut511G3Q+b/kVq7NhqTTrNhxkuU7TrL75DkAagV506l+CF0ahnBDhHRWl6ZFW4/z2KwN9I0N4+07mkjHshOQpCAcIiUrhS93fMmcHXNIy0kjtkosAxsPpH1oe/t9MWSnwZqPYfXHkJcNze+HG0eCXzXAWop5eUGCWLMvhZw8Cz7urrSrG0TnBiF0bBBMiK+HfWIR/7LrRDp9Jqwisoovcwa3lo5lJyFJQThURm4G3+36jpmJMzmReYLIypEMbDSQHrV6YHaxU9G8cyfht7HW1oOLK7R+DNo+DZ6VCg/JzMlj1Z4Ulu84yYodJzmelg1AkzB/OtW3dlZHh0pntb2czcyl14Q/yMzJZ/6wdlT1l+TrLMpEUlBK9QDGASZgitb6rcsc0xcYjXXdyb+11vcWd01JCmVLbn4uC/YvYNrWaew9u5dq3tUYEDWA2yNvx8tspxIHqfthxRvWfgcPf2g3HFo9CuaLR7pordl+LJ3lO06wfMfJws7qIB93OtUPpnODENpFBskiL9co36IZOH0da/YmM2dwa1qEBxgdkrgKhicFpZQJ2AXEA4eBdUA/rXVikWMiga+Bzlrr00qpEK31yeKuK0mhbLJoC78f/p2pW6ey8eRG/N396degH/c2uJfKHpXtc5PjW+CXV2DPUvCtDh1HQsx9YLr8iKSUc+f5ddepy3ZWX2hFyKIvtntr4Q4m/bqXN2+Ppl/LmkaHI65SWUgKbYDRWuvuBdsvAGit3yxyzDvALq31FFuvK0mh7Es4mcBnWz9j5aGVeJg86BPZhwcaPUCoT6h9bnDgD/hltLW0RmAkdPkvNOwFxfRp5OVb2JB0urAv4tLO6s4NQmhZSzqrr2T+30d5YvYm7mtVk9f7RBsdjrgGZSEp3An00Fo/XLB9P9BKaz2syDFzsbYm2mJ9xDRaa72ouOtKUnAee8/sZfq26fy07ye01nSP6M6gxoOurQDfpbSGHT/DsjGQvBNCW0DX0VCrg02nX66z2tfDlY71Q4iPqkLH+sGyoFCBxKNp3P5/q2hc3Z8vH2ktidNJOUtS+AnIBfoCYcBvQLTW+swl1xoMDAaoWbNmi6SkJIfELBzjeMZxZiXO4ptd31gL8FVvy6DGg7ih6g3XP2IpPw/+ng0r34S0I1CnC3QdBdWa2nyJC53VSxOPs2z7SVIycjCbFK1rB9Itqgpdo6pQzb9iztRNzcih18d/kJevmfdEWxnV5cTKQlKw5fHRJOBPrfW0gu1lwEit9borXVdaCs7r7PmzfL3za2Ztn0VqdiqNAxszsPFAutTscn0F+ABys2Hdp/D7e5B1GhrfAZ1fhoCrq9aZb9FsOniapYknWJJ4gv3JGQBEh/oTH1WF+KgqNKhaMcqA5+VbGDD1L9YnneabR9vQtEalkk8SZZbdkkLBc//XgCxgEdAEGK61nlXCea5YHw11AY5g7Wi+V2u9rcgxPbB2Pj+glAoCNgExWuuUK11XkoLzu7QAX5PgJrwa9yq1K9mh3HL2WVg1HtZOhPwcaPEgdHgefKtc9aW01uw9dY4liSdYmniChILRTGGVPQsTRMuIAFxN5fNxyqs/JfLZH/t5766m3NEizOhwxHWyZ1JI0FrHKKX6ALcAzwC/aa1LbJ8rpW4CPsTaXzBVa/26UmoMsF5rPU9Zf916D+gB5AOva63nFHdNSQrlR74ln5/3/8w7694hMzeTITFDeKDRA/aZ55B+HH59BzbOAJMbtBkKcU9Yh7Reo5Pp2SzbfpKliSf4Y08yOXkW/D3NdGlg7YfoUC8Y73JSm+n7jYd55uu/Gdg2glG3NjI6HGEH9kwKW7XWjZVSU4BvtdaLlFJ/25IUHEGSQvmTnJXMm3++yZKkJTQMaMirbV+1T2c0QMpeWP4abPsePAOg/bNww8Ngvr5n4xnn8/h99ymWJFrnRJzJzMXN1YW2dQKJj6pK14YhhPg5z/P33HwLR05ncSAlgz0nz/HO4p20qFmZmQ+1xFxOW0IVjT2TwlvAbVgfH7UEKgE/aa1b2SPQqyVJofxamrSU19a+Rtr5NB6KfojBTQZf/3oOFxzdZB2ptHc5+NeAji9A03vgevsysD57X59k7YdYmniCg6mZAMTUqER8VBW6RVWhboiP4f0Q5/PyOZSaRVJKBgdSMi/6efh0FvmWf74L6ob48NXg1gTKCnnlhl07mpVSAcBZrXW+UsoL8NNaH7dDnFdNkkL5dib7DO+se4f5++ZTt1JdxsSNITrYjuPi9/1qneNwdCMEN4Au/4P6NxU7x+FqaK3ZdeIcS7YdZ+n2E2w+fBaAiEAvujWqSnxUFZrXrIzJQWU3snLySUrN4EByJgdTi3z5J2dy9GwWRf9393V3JSLIm/BALyICC34WbAf7uBuexIR92bOlcBewSGudrpR6GWgOvKa13mifUK+OJIWK4bfDv/HKmldIzkrmgagHGBIzBA9XOz2O0RoSf4Tlr0LKHqjRyjrHITzOPtcv4vjZbJZut7Yg1uxNJjdfE+jtRueCfoj2kcF4ul1dayU9O5eklEySUjI5kJJx0W/8J9LOX3RsgLcbNQO8iAj0IjzQm4iggp+B3lT2MssXfwViz6SwWWvdRCnVDusopHeB/8njI+Fo6TnpvLf+Pb7b/R3hfuGMiRtD8yrN7XeD/DxImGVd5Cf9GNRoba2p1LDXFUtnXI/07Fx+3XWKpQX9EOnZeXiYXWhXN5huUVXo0jCk8HHNmcycIl/6//xMSskg+VzORdcN9nX/50s/8J8v/ZqBXvh7ygQ8YWXPpLBJa91MKfUmsEVr/eWFffYK9mpIUqh41hxdwytrXuHouaP0a9CPp5o/Zb9iewA5mbBhOvz1CZw+AH6h1s7oFg+Cl2OKvuXmW/hrf2phP8SRM1koBXWDfTiZfp6zWbkXHV/d34OahY95/vnyDw/0KjcjnoRj2TMp/IR1nkE81kdHWcBfMvpIlKbM3EzGbRzHlzu+JNQnlNFxo2ldrbV9b2LJty4Puvb/YP+v4OoBTfpCq8egiuOGZWqtSTyWxtLEE2w5fJZqlTwu+vKvEeAlaxaI62bPpOCFdR7BFq31bqVUNaylKJbYJ9SrI0mhYttwYgOjVo8iKS2JOyLv4NnYZ/F187X/jU4kWlsOf38FeVnWmkqtHoN6PewyYkmI0mbv0UdNgfYFm79rrf++zviumSQFkZ2XzcS/JzJj2wyCPIMY1WYUHcJsK4R31TJTrRPg/poCaYehcgS0HGwt2e0pZR+E87BnS+Ep4BHg+4JdfYDJWuuPrjvKayBJQVywNXkr/131X/ac2cOttW9lRMsR+Ltf+4zlYuXnwY6f4M9JcHANmL0h5l5rx3RQpGPuKYQd2XX0EdBGa51RsO0NrNFa23HFdttJUhBF5eTn8OmWT5myeQr+7v681Pol4sPjHXvTownw5yew9VtrfaW6XaHV41CnM7jI7F9RNtmaFGz5F6yw1iW6IL9gnxCGczO5MTRmKHNumUOIVwjPrHyGZ1Y+Q3JWsuNuWj0G+vwfDN8GnV6yrgj3xR0woSX89SmcP+e4ewvhYLa0FJ4BHgB+KNh1GzBDa/2Bg2O7LGkpiCvJteQyY9sMJiZMxNvszciWI7mp1k2On6CVlwOJc62jlo5uBHd/aH6/dVhrQC3H3lsIG9m7o7k50K5g83et9abrjO+aSVIQJdl3Zh//Xf1fNp/aTMewjrzc+mWqeF996exrcmgd/Pl/1hnTlnxrCY3Wj0FEe7uV0hDiWjh0kR2l1EGttSErd0tSELbIt+TzxfYv+GjTR5hdzPznhv/Qp26f0ivrkHYU1n0GG6ZBZgqENLJ2SjfpC+aKuYqbMJajk8IhrXWNa4rsOklSEFfjYNpBRq0exfoT62ldrTWj40YT6hNaegHkZsGWb62jlk5sBc/K1pnSNzwM/rJwjSg90lIQooBFW/hm5ze8v+F9NJrhLYZzd/27cVGlOFJIa0haZe132LkAUBDVyzohrkYrebQkHO66k0JBB/NlPwJe0lo7pihMCSQpiGt19NxRXlnzCquPrqZ5SHPGtB1DuF946QdyOsm6nvTGmdblQ6vFQOvHoVEfcJX1C4Rj2CMpjCruRK31K9cY23WRpCCuh9aauXvm8u66d8mx5PBEsyfo37A/JiNKV+RkwN9zrHMekneCdwjE9AO/MHD3BQ8/cPe75L0fuNpp4SFRoTj08ZGRJCkIeziZeZJX177KykMriQ6KZkzcGOpWrmtMMFrDvhWwdpK1IB8l/D9pci9IEr5Fkob/JQnk0s98L/7czVcm2lUwkhSEKIHWmkUHFvHGn2+QkZvB6LjR9KrTy9ig8nLgfJr1lZ0G59MveX/W+vOynxWcdz4dtKXke7ldLoEU/AyqV7CWtYyUKi8kKQhho5SsFEb8PoI/j/3J082fZlDjQc69IpnW1kdTNieTy3x27gRUrgU3vwd1uxj9JxJ2YM/aRyatdX6xB5UiSQrCEXLzc3lp1Uss3L+Q/g3789wNz5Xu6KSyZt9K+PlZ63KljW6HHm+Cb1WjoxLXwZ61j3Yrpd5VSkVdQxA9lFI7lVJ7lFIjL/P5g0qpU0qphILXw1d7DyHswWwy81b7t+jfsD+zts9ixG8jyMnPKfnE8qp2R3h8NXR8EXb8DB/fAH9Ots7SFuWaLUmhKbALmKKUWquUGqyU8ivpJKWUCZgA9ASigH5XSCxfaa1jCl5TriZ4IezJRbnw/A3P80yLZ1h0YBFDlg3hXE4FLm7n6g4dR8CQNRDaAhY+B592hqOGVbkRpaDEpKC1Ttdaf6q1jgNGAKOAY0qpGUqp4oZrtAT2aK33aa1zgDlAb7tELYSDKKUY2Hggb7R7gw3HNzBo8SDHVlx1BoF14P4f4I7PIP2YNTEseN46x0KUOyUmBaWUSSnVSyn1A/Ah8B4RrIkzAAAgAElEQVRQG5gPLCjm1FDgUJHtwwX7LnWHUmqzUupbpdRlS2cUtE7WK6XWnzp1qqSQhbhut9a5lY+6fMSBtAP0X9CfpLQko0MyllIQfScM/QtiH4K/JsPHLWHr99aObVFu2NSngPU3/He11s201u9rrU9orb8FFl3n/ecDEQUL9iwFZlzuIK31ZK11rNY6Njg4+DpvKYRt2oW247Nun5GZm8mAhQPYmrzV6JCM51kJbh4LjywD3yrw7UCYdQek7jM6MmEntiSFJlrrh7TWqy/9QGv9ZDHnHQGK/uYfVrCv6PkpWuvzBZtTgBY2xCNEqYkOjmZmz5l4unoyaPEgVh1ZZXRIZUNoC3hkBfR8Bw79BRPbwK/vQt75ks8VZZotSSFEKTVfKZWslDqplPpRKVXbhvPWAZFKqVpKKTfgHmBe0QOUUtWKbPYCttscuRClJMI/gs97fk5N35oMWzaM+XvnGx1S2eBispYDH7YO6veEFa/B/7WF/b8ZHZm4DrYkhS+Br4GqQHXgG2B2SSdprfOAYcBirF/2X2uttymlxiilLkwbfVIptU0p9TfwJPDg1f8RhHC8YK9gpvWYRvMqzXnxjxeZvnW60SGVHX7V4K7pcN93YMmFGbfC94/COen/c0a2TF7bXPDMv+i+v7XWTR0a2RXI5DVhpJz8HF7840UWH1jMgKgBPBv7bMWe5Hap3Cz4bSysGgduXtD1FWj+gNRZKgPsOXltoVJqpFIqQikVrpR6HliglApQShlSPlsIo7iZ3Hinwzvc1/A+ZibO5IXfXyA3P9fosMoOsyd0+S88vgqqNoGfnoap3eD4FqMjEzaypaWwv5iPtdbalv4Fu5GWgigLtNZ8tvUzxm0cR5tqbfig0wd4m72NDqts0Ro2fwWLX4Ks09Y1Izq+AO4+RkdWIUlBPCFKwdw9cxm9ejT1A+ozocsEgjyDjA6p7MlMhWWvwIbp4BdqHbHU4GZZba6U2e3xkVLKrJR6smBy2bdKqWFKKbN9whTCud1W9zbGdx7P/rP7GbBwAIfSDpV8UkXjFQC3joNBS8CjEnx1H8zuB2cOGh2ZuAxb+hT+D+v8gYkFrxYF+4QQQIewDkzpNoX0nHT6L+zPtpRtRodUNtVsBY/+Ct1eg/2/woRW8MeHIH0yZYotSeEGrfUDWuvlBa+BwA2ODkwIZ9IkuAkze87Ew+TBoEWDWH30X3M9BYDJDHFPWMtl1OkMv4yCSe0haY3RkYkCtiSFfKVUnQsbBRPXpH6uEJeo5V+Lz2/6nFDfUIYuG8rP+342OqSyq1INuOcLuGc25JyDaT3gx6GQkWJ0ZBWeLUnhOWCFUmqlUupXYDnwrGPDEsI5hXiFML3HdGKCYxj5+0hmbLtsOS9xQYObYOif0PYp+HsOfBwLm2ZJkT0DFZsUlFIuQBYQiXXG8RNAfa31ilKITQin5Ofmx6T4ScSHxzN2/VjeW/8eFlvWTK6o3Lwhfgw8+pt1begfh8K0m+CkVL0xQrFJQWttASZorc9rrTcXvKTilRAlcDe5826Hd7mn/j1M3zadl/54iVyLdKgWq0ojGLgQen0Ep7bDpHaw8i2wSEItTbY8PlqmlLpDOfVK5kKUPpOLiRdbvciTzZ7kp30/8cSyJ8jMzTQ6rLLNxQWaD4Bh661rQ698E76+H85X4BXwSpktSeFRrEXwziul0pRS6UqpNAfHJUS5oJTikSaPMCZuDGuPrWXQ4kGkZElnaom8g+D2ydDjLdi5AKZ2l3kNpcSW5Th9tdYuWms3rbVfwXaJazQLIf7RJ7IP4zqNY++ZvdZJbukyya1ESllLY9z3DZw5BJM7ydDVUmDLjOZltuwTQhTvxho38mm3Tzmbc5b7F9zP9hTpSLVJ3a7Wld48/K1luTd+bnRE5doVk4JSyqOgCmqQUqryhaqoSqkILr/WshCiBDEhMczsMROzyczAxQNZe2yt0SE5h6BIa2KIaAvzhlmL7FlkupQjFNdSeBTYADQo+Hnh9SPwseNDE6J8ql2pNrN6zqKadzUe/+VxFu5faHRIzsGzsnUhn1aPwZqP4cu+kH3W6KjKnSsmBa31OK11LeA/WuvaWutaBa+mWmtJCkJchyreVZjeYzpNgprw/G/PMytxltEhOQeTK/R8G275EPathCldIWWv0VGVKzaVzlZKxQERgOuFfVrrmY4L68qkdLYoT87nn2fkbyP55eAvDGo8iKebP42M/rbR/t/h6wGgLdB3BtTuaHREZZo9S2d/DowF2mEthHcDUOKFhRAlcze5M/bGsfSt15epW6fy8qqXybPkGR2Wc6jVHh5ZDr7V4PPb4a9PjY6oXHAt+RBigSjtbKvxCOEkTC4mXm79MkFeQUxMmIjZxcyoNqOkxWCLgFrw0BL4/hFY8B9raYyeb1ursYprYktS2ApUBY45OBYhKiylFI83fZzc/Fw+3fIpAR4BPNn8SaPDcg4efnDPl7BsDKz6EJJ3Qd+Z1sV9xFWzZUZzEJColFqslJp34WXLxZVSPZRSO5VSe5RSI4s57g6llFZKyWMpUaE90ewJ7oi8g0+3fMoX278wOhzn4WKC+Fegzydw6E/4tDOc3GF0VE7JlpbC6Gu5sFLKBEwA4oHDwDql1DytdeIlx/kCTwF/Xst9hChPlFK83Pplzpw/w1t/vUVl98rcVPsmo8NyHk3vgYDaMOc+68ikO6dCvW5GR+VUipu81gBAa/0rsFZr/euFF2BLpdSWwB6t9T6tdQ4wB+h9meNeBd4Gsq86eiHKIVcXV97u8DaxVWJ56Y+XWHVkldEhOZcaLWHwCmt/w5d9YdV4WZ/hKhT3+OjLIu8vLTgy0YZrhwJFC7wc5pKZ0Eqp5kANrbUsUSVEEe4md8Z3Hk+dSnUYvnI4W05tMTok5+IfBoMWQVQvWPpfmDsE8qTqvy2KSwrqCu8vt33VChbweR8bVnFTSg1WSq1XSq0/derU9d5aCKfg6+bLpPhJBHoEMmTZEPad3Wd0SM7FzRvunA4dX4C/v7TWTTp30uioyrzikoK+wvvLbV/OEaBGke2wgn0X+AKNgZVKqQNAa2De5TqbtdaTtdaxWuvY4OBgG24tRPkQ5BnE5PjJuCgXHl36KMczjhsdknNxcYGOI+Gu6XBss7XS6rHNRkdVphWXFMKUUuOVUh8VeX9h25aCeOuASKVULaWUG3APUDhqSWt9VmsdpLWO0FpHAGuBXlprma4sRBE1/Gowqesk0nPSeWzpY5w9L/V+rlqjPtbHSWjr2gyJNg2grJCKSwrPYS2At77I+wvbz5d0Ya11HjAMWAxsB77WWm9TSo1RSvW63sCFqEgaBjZkfKfxHEw/yNBlQ8nKyzI6JOdTPcY6Azokyrqa26/vSAf0ZdhU+6gskdpHoiL7JekXnv31WdpWb8u4zuMwu8jM3auWmw3zn4LNc6xLfvaeAG5eRkflcHarfSSEKDu6hnfl5dYv8/uR3xm1ahQWLYvaXzWzB/SZBF1fgW0/wLSekHbU6KjKDEkKQjiZu+rdxbCYYczfN5/3179vdDjOSSlo9zT0mw0pe6wd0Ic3GB1VmSBJQQgnNLjJYPo16MeMxBlM2zrN6HCcV/2e8NBScHWzthg2f2N0RIazpXT2O0opP6WUWSm1TCl1SinVvzSCE0JcnlKKkS1H0jOiJ+9veJ+5e+YaHZLzqhIFj6yEsFj4/mFrYT1LxX0sZ0tLoZvWOg24BTgA1MU6GkkIYSAX5cLr7V6nTbU2jF49mpWHVhodkvPyDoT750LzB+D39+Cr/nA+3eioDGFLUrhQNO9m4ButtQySFqKMMJvMfNDpAxoENOA/v/6HjSc2Gh2S83J1g1vHQc93YNdC+Kw7nE4yOqpSZ0tS+EkptQNoASxTSgUjxeuEKDO8zd5M7DqRat7VGLZ8GLtO7zI6JOelFLR6FO77Fs4ehk87QdJqo6MqVSUmBa31SCAOiNVa5wIZXL7aqRDCIAEeAXwS/wmeJk8eW/oYR84dKfkkcWV1u8Ajy8CzMszoVaE6oG3paL4LyNVa5yulXgZmAdUdHpkQ4qpU96nOpPhJZOdn8+jSR0nJSjE6JOcWFAkP/wI1W8MPg61zGioAWx4f/Vdrna6Uagd0BT4D/s+xYQkhrkVk5UgmdJnA8YzjDFk2hIzcDKNDcm6eleHer6BGK/juYdixwOiIHM6WpJBf8PNmYHLB2gdujgtJCHE9moU0470b32Nn6k6eWvEUOfk5Rofk3Ny84d6voWoT+OYB2LPM6IgcypakcEQp9QlwN7BAKeVu43lCCIPcWONGXol7hT+P/cmLf7xIviW/5JPElXn4Qf/vIKi+danPA38YHZHD2PLl3hdrpdPuWuszQAAyT0GIMq933d482+JZFh9YzFt/vYWzFb8sc7wCYMBcqFQTvugLh/4yOiKHsGX0USawF+iulBoGhGitlzg8MiHEdXuw8YM82OhB5uycw6TNk4wOx/l5B8ED88C3Csy6E44mGB2R3dky+ugp4AsgpOA1Syn1hKMDE0LYx/AWw+lVpxcTEyby9c6vjQ7H+flWhQHzwMMfPu8DJxKNjsiubHl89BDQSmv9P631/7Aum/mIY8MSQtiLi3JhdNxoOoR14LW1r7HkgDT0r1ulGvDAj+DqDjN7Q/JuoyOyG1uSguKfEUgUvFeOCUcI4QhmFzNjbxxL0+CmjPx9JH8e+9PokJxfQG1riwFtneCWut/oiOzClqQwDfhTKTVaKTUa61rKnzk0KiGE3Xm6evJxl48J9wvnqRVPkZhSvh57GCK4nrWQXl4WzOxlLY3h5GzpaH4fGAikFrwGaq0/dHRgQgj783f3Z1LXSfi5+fH4L49zMO2g0SE5v6qNof/3kHXG2mJIP2F0RNel2KSglDIppXZorTdqrccXvDaVVnBCCPur4l2FT+I/QWvN4KWDOZV5yuiQnF9oc2sRvfTj1j6GDOctMVJsUtBa5wM7lVI1SykeIUQpqOVfi4ldJ5KancpjvzxGWk6a0SE5v5qt4N45cHo/fN4bsk4bHdE1saVPoTKwrWDVtXkXXo4OTAjhWI2DGvNhpw/Zd3YfTy5/kuw8qYh/3Wp1gLu/gFM7rfMYnHChHpsK4mFddW0M8F6RV4mUUj2UUjuVUnuUUiMv8/ljSqktSqkEpdQfSqmoqwleCHF94qrH8Ua7N9h4YiPP//Y8eZY8o0NyfpFd4a7pcHSTdeZzTqbREV2VKyYFpVRdpVRbrfWvRV9Yh6SW2MWulDIBE4CeQBTQ7zJf+l9qraO11jHAO8D71/wnEUJck561ejKi5QhWHFrBq2tflXIY9tDgZrjjUzi0Fub0g1znaYUV11L4ELjcg8azBZ+VpCWwR2u9T2udA8zhksV5CtZ+vsAbkH+NQhjgvob3MbjJYL7f/T3jN403OpzyofEd0HsC7FsJXw+APOeoVutazGdVtNZbLt2ptd6ilIqw4dqhwKEi24eBVpcepJQaCjyDtRx358tdSCk1GBgMULOm9HkL4QjDYoaRmp3KlC1TCPAI4P6o+40OyfnF3Au5WfDzM/D9w3DHVDAV97VrvOJaCpWK+czTXgForSdoresAI4CXr3DMZK11rNY6Njg42F63FkIUoZTi5VYv07VmV95Z9w7Tt043OqTy4YaHoPsbkPgj/DgEyngZ8+KSwnql1L9qHCmlHgY22HDtI0CNItthBfuuZA5wmw3XFUI4iMnFxDsd3qF7RHfe2/AeH236SPoY7KHNUOj8Mmz+Cn56Gsrw32lx7ZingR+UUvfxTxKIxfqYp48N114HRCqlamFNBvcA9xY9QCkVqbW+UEnqZqD8VJUSwkmZTWbebv82PmYfJm+ezLmcc4xoOQIXJWtrXZcOz1k7nH8fC66e0PNtUGWvjNwVk4LW+gQQp5TqBDQu2P2z1nq5LRfWWucVrL+wGDABU7XW25RSY4D1Wut5wDClVFcgFzgNPHAdfxYhhJ2YXEyMajMKb7M3MxNnci73HK/EvYKrS9l+Hl7mdX7Z2sewdgKYPaDrK2UuMZT4X1hrvQJYcS0X11ovABZcsu9/Rd4/dS3XFUI4nlKK/8T+Bx83HyYmTCQzN5O3O7yNm0mWaL9mSkH3160F9FaNA7M3dBxhdFQXkfagEOKKlFI83vRxRtwwgl8O/sITy58gM9e5JmOVOUrBTe9B03th5RvW5FCGSFIQQpSof1R/xsSNYe2xtTy69FGplXS9XFyg98fQ6HZY+j/4c7LRERWSpCCEsEmfyD682+FdtqZs5aHFD5GS5byVQMsEFxPcPhnq3wwLn4MNM4yOCJCkIIS4Ct0iuvFR5484cPYADy56kOMZx40OybmZzHDXNKjTBeY/BZuNX0NbkoIQ4qq0C23HpPhJJGclM2DhAJLSkowOybm5usPdsyCiHfzwmHWSm4EkKQghrlqLKi34rPtnZOdl88DCB9h1epfRITk3Ny/oNwdCW8C3g2DXYsNCkaQghLgmUYFRTO8xHZOLiYGLBvL3qb+NDsm5uftA/2+hSmP46n7Ye00zAa6bcrYp7LGxsXr9+vUX7cvNzeXw4cNkZztPedrS4uHhQVhYGGaz2ehQRDl15NwRHlnyCMlZyXzU+SNaVftX3UtxNTJTYfotkLoP7v8ewuPsclml1AatdWyJx5WHpLB//358fX0JDAxElbHZgUbSWpOSkkJ6ejq1atUyOhxRjp3KPMXgpYM5mHaQsTeOpVPNTkaH5NzOnYRpN0H6MRjwI4SV+F1eIluTQrl4fJSdnS0J4TKUUgQGBkoLSjhcsFcw07pPo17legxfOZyf9/1sdEjOzScEHpgH3kEw63Y4VnqP5spFUgAkIVyB/L2I0lLJoxJTuk+heZXmvPD7C3y90/jhlU7NrzoMmAduvvB5Hzi5vVRuW26SgtFMJhMxMTE0btyYW2+9lTNnzgBw4MABlFJ89NFHhccOGzaM6dOnA/Dggw8SGhrK+fPnAUhOTiYiIqK0wxfCLrzN3kzsMpEOYR14de2rfLblM6NDcm6Vw60tBhdXmNkbUvY6/JaSFOzE09OThIQEtm7dSkBAABMmTCj8LCQkhHHjxpGTc/nl+EwmE1OnTi2tUIVwKA9XDz7o9AE9I3ry4cYP+XDDh7Imw/UIrGNtMWgLHFzr8NtJUnCANm3acOTIP+sJBQcH06VLF2bMuPw09qeffpoPPviAvLy80gpRCIcyu5h5s/2b3FnvTj7b+hmv//k6Fm0xOiznFdIAhq2HZvc5/Fblrjj6K/O3kXjUvsW6oqr7MerWRjYdm5+fz7Jly3jooYcu2j9ixAh69uzJoEGD/nVOzZo1adeuHZ9//jm33nqrXWIWwmgmFxP/a/0/fM2+TNs2jYzcDF5t+6qsyXCtPItbIdl+pKVgJ1lZWcTExFC1alVOnDhBfHz8RZ/Xrl2bVq1a8eWXX172/BdeeIF3330Xi0V+mxLlh1KK4S2G82SzJ/lp3088s/IZzuefNzosUYxyl7Jt/Y3e3i70KWRmZtK9e3cmTJjAk08+edExL774InfeeSc33njjv86PjIwkJiaGr7+WERuifFFK8UiTR/A2e/PmX28ydNlQxncaj5fZy+jQxGVIS8HOvLy8GD9+PO+9996/+ggaNGhAVFQU8+fPv+y5L730EmPHji2NMIUodfc2vJfX273OuuPreGTpI5w9f9bokMRlSFJwgGbNmtGkSRNmz579r89eeuklDh8+fNnzGjVqRPPmzR0dnhCG6VWnF+/f+D7bU7YzaPEgkrOSjQ5JXKJclLnYvn07DRs2NCiisk/+fkRZs/roap5e8TQhXiF8Gv8p1XyqGR1SuVehylwIIZxLXPU4JsdPJjUrlQGLBnDg7AGjQxIFHJoUlFI9lFI7lVJ7lFIjL/P5M0qpRKXUZqXUMqVUuCPjEUKUHTEhMUztMZWc/BweWPQAO1J3GB2SwIFJQSllAiYAPYEooJ9SKuqSwzYBsVrrJsC3wDuOikcIUfY0CGjA9B7TMbuYGbRoEAknE4wOqcJzZEuhJbBHa71Pa50DzAF6Fz1Aa71Ca51ZsLkWCHNgPEKIMqiWfy1m9pxJZY/KDF46mDVH1xgdUoXmyKQQChwqsn24YN+VPAQsdGA8QogyqrpPdWb0nEEN3xoMXTaUZQeXGR1ShVUmOpqVUv2BWODdK3w+WCm1Xim1/tSpU6UbnBCiVAR5BjG1+1QaBjbk2ZXPMn/v5efzCMdyZFI4AtQosh1WsO8iSqmuwEtAL631Zee/a60na61jtdaxwcHBDgn2evn4+Pxr386dO+nYsSMxMTE0bNiQwYMHs3jxYmJiYoiJicHHx4f69esTExPDgAEDWLlyJUoppkyZUniNhIQElFIyqU1UCP7u/nwa/ymxVWJ58Y8Xmbp1KvmWfKPDqlAcmRTWAZFKqVpKKTfgHmBe0QOUUs2AT7AmhJMOjMUQTz75JMOHDychIYHt27fzxBNP0L17dxISEkhISCA2NpYvvviChIQEZs6cCUDjxo0vKnUxe/ZsmjZtatQfQYhS52X2YkLXCcSHx/PBhg/o93M/Np/abHRYFYbDkoLWOg8YBiwGtgNfa623KaXGKKV6FRz2LuADfKOUSlBKzbvC5ZzSsWPHCAv7p+88Ojq6xHPCw8PJzs7mxIkTaK1ZtGgRPXv2dGSYQpQ57iZ33rvxPcbeOJaUrBT6L+jPK2tekdIYpcChBfG01guABZfs+1+R913tftOFI+H4Fvtes2o09Hzrqk8bPnw4nTt3Ji4ujm7dujFw4EAqVSq5/O2dd97JN998Q7NmzWjevDnu7u7XErUQTk0pRfeI7rQLbcfEhIl8sf0LliUtY3iL4fSu2xsXVSa6RMsd+Vt1oIEDB7J9+3buuusuVq5cSevWrQuX3SxO3759+eabb5g9ezb9+vUrhUiFKLu8zd48d8NzfHXLV4T7hfO/1f/jwUUPsjN1p9GhlUvlrnT2tfxG70jVq1dn0KBBDBo0iMaNG7N161ZatGhR7DlVq1bFbDazdOlSxo0bx+rVq0spWiHKrvoB9ZnRcwY/7vmRDzZ8wN0/3c19De9jSMwQvM3eRodXbkhLwYEWLVpEbm4uAMePHyclJYXQ0OKmavxjzJgxvP3225hMJkeGKIRTcVEu9Insw/w+8+kT2YfPEz+n1w+9WHRgkawDbSflr6VgkMzMzIs6lZ955hkOHz7MU089hYeHBwDvvvsuVatWtel6cXFxDolTiPLA392fUW1G0aduH15b+xrP/foc31f7nhdbvUiEf4TR4Tk1KZ1dAcjfjyjP8i35fLXzKz7a9BHn888zqPEgHo5+GA9XD6NDK1OkdLYQokIwuZi4t+G9zO8zn24R3fhk8yfc9uNt/Hb4N6NDc0qSFIQQ5UKQZxBvtX+Lz7p9hpvJjaHLhvL0iqc5du6Y0aE5FUkKQohypWW1lnx363c83fxpVh9dTe8fe/PZls/Izc81OjSnIElBCFHumE1mHop+iLm959KmWhs+3Pghd86/k3XH1xkdWpknSUEIUW5V96nOuM7j+Ljzx9ZO6MWDeOH3F0jOSjY6tDJLkoIQoty7scaN/ND7BwY3GcziA4vp9UMvZu+YLRVYL0OSgp2YTCZiYmJo2rQpzZs3L5yFfPToUe68804AVq5cyS233PKvc3/66SeaNWtG06ZNiYqK4pNPPuH1118vLLF94doxMTGMHz+e0aNHo5Riz549hdf48MMPUUpx6XBdIYSVp6snTzR7gu97fU+joEa88ecb9Pu5H1tO2blWmrPTWjvVq0WLFvpSiYmJ/9pX2ry9vQvfL1q0SHfo0OFfx6xYsULffPPNF+3LycnR1apV04cOHdJaa52dna137NhxxWtrrfWoUaN0dHS0fvXVVwv3xcXF6UaNGul169b9675l4e9HiLLEYrHohfsX6k5fddLR06P1mNVj9JnsM0aH5VDAem3Dd6y0FBwgLS2NypUrA3DgwAEaN258xWPT09PJy8sjMDAQAHd3d+rXr1/iPW677TZ+/PFHAPbu3Yu/vz9BQUF2iF6I8k8pRY+IHsy7bR79o/rz3e7vuPWHW5m7Z26FL5dR7spcvP3X2+xI3WHXazYIaMCIliOKPSYrK4uYmBiys7M5duwYy5cvt+naAQEB9OrVi/DwcLp06cItt9xCv379cHEpPl/7+flRo0YNtm7dyo8//sjdd9/NtGnTbP4zCSHAx82H5294nt51evPa2tf476r/8sPuH3ip9UvUq1zP6PAMIS0FO/H09CQhIYEdO3awaNEiBgwYYPNvHFOmTGHZsmW0bNmSsWPHMmjQIJvOu+eee5gzZw5z586lT58+1xO+EBXahQqsY+LGsO/sPvrO78vYdWPJyM0wOrRSV+5aCiX9Rl8a2rRpQ3JyMqdOnbL5nOjoaKKjo7n//vupVasW06dPL/GcW265heeee47Y2Fj8/PyuI2IhxIUKrJ1qdGLcpnHMSJzBwgMLGXHDCOLD41FKGR1iqSh3SaEs2LFjB/n5+QQGBpKZmVnssefOnWP9+vV07NgRgISEBMLDw226j5eXF2+//Tb16lXMZq4QjlDJoxKj2ozitrq38fra13n212fxdPXE180XPze/i35euq/wvfs/n/uYfZxqlThJCnZyoU8BrCO6ZsyYcdm1EJYtW3ZRie3Zs2fzzjvv8Oijj+Lp6Ym3t7dNrYQL7rnnnuuOXQjxb02Dm/LlzV8yf+989p7ZS1pOGuk56aTnpHMy8yR7zuwp3NZc+VGxQuHj5nNR0ig2sbj74Wv2LUwuHiaPUm2lSOnsCkD+foRwHIu2kJGbQXpOemHiSMtJI+18QRLJTf/n/YXPCl7pOelk5WUVe31XF9fChDIkZgg9a/W8pjhtLZ0tLQUhhLgOLsql8Df+6lS/6vNzLbmFCSM9x5pA0nLTCt8XTSb+7v4O+BNczKFJQSnVAxgHmIApWuu3Lo5eK1YAAAYpSURBVPm8A/Ah0AS4R2v9rSPjEUKIssbsYibAI4AAjwCjQwEcOCRVKfX/7d1bjJx1Gcfx74+2OoKJYuBGltq1WjaNhtLIQWogHBI1GjQmTTiowWjQiAXEQ8ALLrjhAmJIjIINh16Ih1q5MAQRwiFwgQgt0FrKKaWUBQxlOWhIOFR+Xrz/nZ1ZQrvtdva/u+/vc7Mz78z7zjP/7Mwz7/t/3+dZAPwa+DKwHDhL0vJJT9sJnAv8flBxRETE1A1yT+E44Gnb2wEk/RH4GvDY+BNs7yiPvTvdF7PdmlPG9sVcmzOKiLoGeZ7UEcBzPfdHy7IDrtPpMDY2li/ASWwzNjZGp5NetRExNXNiolnSecB5AIsXL37P40NDQ4yOju7TxWJt0el0+k6BjYjYk0EmheeBI3vuD5Vl+8z2WmAtNKekTn580aJFDA8P78+mIyKixyAPHz0IfFrSsKQPAGcCfx3g60VExDQNLCnY3g38CPg7sA1Yb3urpMslnQEg6VhJo8Bq4LeStg4qnoiI2LuBzinYvhW4ddKyy3puP0hzWCkiImaBOVfmQtIu4Nn9XP0wIB27J2Q8+mU8JmQs+s2H8fiE7cP39qQ5lxSmQ9JDU6n90RYZj34ZjwkZi35tGo+5U881IiIGLkkhIiK62pYU1tYOYJbJePTLeEzIWPRrzXi0ak4hIiL2rG17ChERsQetSQqSviTpCUlPS7qkdjy1SDpS0t2SHpO0VdKFtWOaDSQtkPSwpFtqx1KbpI9K2iDpcUnbJH2+dky1SPpx+Zz8S9IfJM376pKtSApT7O3QFruBn9heDpwAnN/iseh1Ic2V99E0xrrN9ghwNC0dF0lHABcAn7P9GZpmYfO+KXorkgI9vR1svw2M93ZoHdsv2t5Ubv+X5gM/kJLmc4WkIeArwHW1Y6lN0keAk4DrAWy/bfu1ulFVtRD4kKSFwMHAC5XjGbi2JIUZ6+0wl0haAhwDPFA3kuquBn4OTLvZ0zwwDOwCbiyH066TdEjtoGqw/TxwFU2HyBeB123fXjeqwWtLUohJJH0Y+Atwke3/1I6nFklfBV6yvbF2LLPEQmAlcI3tY4A3gFbOwUk6lOaIwjDwceAQSd+sG9XgtSUpHLDeDvOBpEU0CeEm2zfXjqeyVcAZknbQHFY8VdLv6oZU1Sgwant873EDTZJoo9OBZ2zvsv0OcDNwYuWYBq4tSSG9HQo1jayvB7bZ/mXteGqzfantIdtLaP4v7rI9738Nvh/b/waek3RUWXQaPX3VW2YncIKkg8vn5jRaMOk+J9pxTpft3ZLGezssAG6w3dbeDauAbwFbJD1Slv2ilDmPAFgD3FR+QG0HvlM5nipsPyBpA7CJ5qy9h2nBlc25ojkiIrracvgoIiKmIEkhIiK6khQiIqIrSSEiIrqSFCIioitJIaKHpCsknSLp65IunaHX3CHpsJl4rYi9SVKI6Hc88A/gZODeyrFEzLgkhQhA0pWSNgPHAvcD3wOukXSZpKWSbpO0UdJ9kkbKOuskXSvpIUlPljpKSOpIulHSllJU7pSyfIGkq0pt/s2S1vSEsEbSprLOyAy//YiuVlzRHLE3tn8maT3wbeBi4B7bqwAk3Qn8wPZTko4HfgOcWlZdQlOafSlwt6RPAec3m/Rnyxf87ZKW0VwZvARYUa6y/1hPCC/bXinph8BPaZJSxIxLUoiYsBJ4FBih1Lgp1WRPBP7clL8B4IM966y3/S7wlKTtZd0vAL8CsP24pGeBZTQF1q61vbs89krPdsYLE24EvnHg31rE1CQpROtJWgGso6me+zJNMxWV2lAnA6/ZXvE+q0+uE7O/dWPeKn//Rz6XUVHmFKL1bD9SvvSfpGnXehfwRdsrbL8OPCNpNTSZQtLRPauvlnSQpKXAJ4EngPuAc8rzlwGLy/I7gO+XLl5MOnwUMSskKUQAkg4HXi2HgkZs95aLPgf4rqRHga30t3LdCfwT+BvNvMObNHMOB0naAvwJONf2WzTtPncCm8u2zh70+4rYV6mSGrGfJK0DbrG9oXYsEQdK9hQiIqIrewoREdGVPYWIiOhKUoiIiK4khYiI6EpSiIiIriSFiIjoSlKIiIiu/wMBNRf16+gd1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(n_epoch), rnn_loss_list)\n",
    "plt.plot(range(n_epoch), lstm_loss_list)\n",
    "plt.plot(range(n_epoch), bilstm_loss_list)\n",
    "plt.legend([\"RNN\", \"LSTM\", \"BiLSTM\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cv-q0dA1fqhN"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2gEjpREfqhN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習成功です。次のステップに進んでください。\n"
     ]
    }
   ],
   "source": [
    "if average_bilstm_loss > 0.2:\n",
    "    print(\"RNNの実装に間違いがあります。問4を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlswOIfWCvFR"
   },
   "source": [
    "## Seq2Seq\n",
    "## データセット用意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhjiJjDmfqhP"
   },
   "source": [
    "Seq2seq を用いてタスクを解いていきます。\n",
    "\n",
    "今回用いるデータセットは、足し算の数式を並べたものになります。数式とその答を全て文字列として考え、足し算の式をLSTMによって一文字ずつ読み込み、その答えを一文字ずつ出力していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "000wqFK6CvFS"
   },
   "outputs": [],
   "source": [
    "id_to_char = {}\n",
    "char_to_id = {}\n",
    "\n",
    "\n",
    "def _update_vocab(txt):\n",
    "    chars = list(txt)\n",
    "\n",
    "    for i, char in enumerate(chars):\n",
    "        if char not in char_to_id:\n",
    "            tmp_id = len(char_to_id)\n",
    "            char_to_id[char] = tmp_id\n",
    "            id_to_char[tmp_id] = char\n",
    "\n",
    "def load_sequence(file_name='addition.txt'):\n",
    "    file_path = './' + file_name\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print('No file: %s' % file_name)\n",
    "        return None\n",
    "\n",
    "    questions, answers = [], []\n",
    "\n",
    "    for line in open(file_path, 'r'):\n",
    "        idx = line.find('_')\n",
    "        questions.append(line[:idx])\n",
    "        answers.append(line[idx:-1])\n",
    "\n",
    "    # create vocab dict\n",
    "    for i in range(len(questions)):\n",
    "        q, a = questions[i], answers[i]\n",
    "        _update_vocab(q)\n",
    "        _update_vocab(a)\n",
    "\n",
    "    # create np array\n",
    "    x = np.zeros((len(questions), len(questions[0])), dtype=np.int)\n",
    "    t = np.zeros((len(questions), len(answers[0])), dtype=np.int)\n",
    "\n",
    "    for i, sentence in enumerate(questions):\n",
    "        x[i] = [char_to_id[c] for c in list(sentence)]\n",
    "    for i, sentence in enumerate(answers):\n",
    "        t[i] = [char_to_id[c] for c in list(sentence)]\n",
    "\n",
    "    # shuffle\n",
    "    indices = np.arange(len(x))\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    t = t[indices]\n",
    "\n",
    "    # 10% for validation set\n",
    "    split_at = len(x) - len(x) // 10\n",
    "    (x_train, x_test) = x[:split_at], x[split_at:]\n",
    "    (t_train, t_test) = t[:split_at], t[split_at:]\n",
    "\n",
    "    return (x_train, t_train), (x_test, t_test)\n",
    "\n",
    "\n",
    "def get_vocab():\n",
    "    return char_to_id, id_to_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uFQosKWCvFT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_sequence('addition.txt')\n",
    "char_to_id, id_to_char = get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djem-PB6CvFV"
   },
   "source": [
    "## ネットワーク定義\n",
    "問5. <font color=\"Red\">以下の Seq2seq クラスを完成させてください。</font>\n",
    "\n",
    "  - Encoderクラスは、各時刻での入力を順伝播させた後、最後の時刻に対応する出力をDecoder クラスに渡します。\n",
    "  - Decoderクラスの順伝播では、まずEncoderクラスの出力を内部状態としてセットし、入力系列データを順伝播させていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TZQsu3QCvFV"
   },
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    " \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(D, H, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:,-1,:] ######問4.1######\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(D, H, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h) ######問4.2######\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "class Seq2seq():\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs) \n",
    "        score = self.decoder.forward(decoder_xs, h) \n",
    "        loss = self.softmax.forward(score, decoder_ts) \n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnZqVX0ECvFW"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 8\n",
    "max_grad = 5.0\n",
    "\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "optimizer = Adam()\n",
    "\n",
    "data_size = len(x_train)\n",
    "max_iters = data_size // batch_size\n",
    "loss_list = []\n",
    "eval_interval = 50\n",
    "current_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkmNOSrrCvFY"
   },
   "source": [
    "### 学習、評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Shwm9X8OCvFZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | loss 2.57\n",
      "| epoch 1 |  iter 51 / 351 | loss 2.29\n",
      "| epoch 1 |  iter 101 / 351 | loss 1.89\n",
      "| epoch 1 |  iter 151 / 351 | loss 1.81\n",
      "| epoch 1 |  iter 201 / 351 | loss 1.78\n",
      "| epoch 1 |  iter 251 / 351 | loss 1.76\n",
      "| epoch 1 |  iter 301 / 351 | loss 1.75\n",
      "| epoch 1 |  iter 351 / 351 | loss 1.74\n",
      "| epoch 2 |  iter 1 / 351 | loss 1.74\n",
      "| epoch 2 |  iter 51 / 351 | loss 1.73\n",
      "| epoch 2 |  iter 101 / 351 | loss 1.72\n",
      "| epoch 2 |  iter 151 / 351 | loss 1.71\n",
      "| epoch 2 |  iter 201 / 351 | loss 1.70\n",
      "| epoch 2 |  iter 251 / 351 | loss 1.68\n",
      "| epoch 2 |  iter 301 / 351 | loss 1.66\n",
      "| epoch 2 |  iter 351 / 351 | loss 1.65\n",
      "| epoch 3 |  iter 1 / 351 | loss 1.62\n",
      "| epoch 3 |  iter 51 / 351 | loss 1.63\n",
      "| epoch 3 |  iter 101 / 351 | loss 1.60\n",
      "| epoch 3 |  iter 151 / 351 | loss 1.57\n",
      "| epoch 3 |  iter 201 / 351 | loss 1.54\n",
      "| epoch 3 |  iter 251 / 351 | loss 1.50\n",
      "| epoch 3 |  iter 301 / 351 | loss 1.47\n",
      "| epoch 3 |  iter 351 / 351 | loss 1.44\n",
      "| epoch 4 |  iter 1 / 351 | loss 1.45\n",
      "| epoch 4 |  iter 51 / 351 | loss 1.42\n",
      "| epoch 4 |  iter 101 / 351 | loss 1.39\n",
      "| epoch 4 |  iter 151 / 351 | loss 1.37\n",
      "| epoch 4 |  iter 201 / 351 | loss 1.35\n",
      "| epoch 4 |  iter 251 / 351 | loss 1.32\n",
      "| epoch 4 |  iter 301 / 351 | loss 1.31\n",
      "| epoch 4 |  iter 351 / 351 | loss 1.29\n",
      "| epoch 5 |  iter 1 / 351 | loss 1.26\n",
      "| epoch 5 |  iter 51 / 351 | loss 1.28\n",
      "| epoch 5 |  iter 101 / 351 | loss 1.26\n",
      "| epoch 5 |  iter 151 / 351 | loss 1.24\n",
      "| epoch 5 |  iter 201 / 351 | loss 1.22\n",
      "| epoch 5 |  iter 251 / 351 | loss 1.21\n",
      "| epoch 5 |  iter 301 / 351 | loss 1.19\n",
      "| epoch 5 |  iter 351 / 351 | loss 1.18\n",
      "| epoch 6 |  iter 1 / 351 | loss 1.17\n",
      "| epoch 6 |  iter 51 / 351 | loss 1.16\n",
      "| epoch 6 |  iter 101 / 351 | loss 1.16\n",
      "| epoch 6 |  iter 151 / 351 | loss 1.14\n",
      "| epoch 6 |  iter 201 / 351 | loss 1.14\n",
      "| epoch 6 |  iter 251 / 351 | loss 1.12\n",
      "| epoch 6 |  iter 301 / 351 | loss 1.12\n",
      "| epoch 6 |  iter 351 / 351 | loss 1.10\n",
      "| epoch 7 |  iter 1 / 351 | loss 1.08\n",
      "| epoch 7 |  iter 51 / 351 | loss 1.09\n",
      "| epoch 7 |  iter 101 / 351 | loss 1.08\n",
      "| epoch 7 |  iter 151 / 351 | loss 1.08\n",
      "| epoch 7 |  iter 201 / 351 | loss 1.08\n",
      "| epoch 7 |  iter 251 / 351 | loss 1.07\n",
      "| epoch 7 |  iter 301 / 351 | loss 1.04\n",
      "| epoch 7 |  iter 351 / 351 | loss 1.04\n",
      "| epoch 8 |  iter 1 / 351 | loss 1.03\n",
      "| epoch 8 |  iter 51 / 351 | loss 1.05\n",
      "| epoch 8 |  iter 101 / 351 | loss 1.05\n",
      "| epoch 8 |  iter 151 / 351 | loss 1.02\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    # シャッフル\n",
    "    idx = np.random.permutation(np.arange(data_size))\n",
    "    x = x_train[idx]\n",
    "    t = t_train[idx]\n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "#         params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "        optimizer.update(model.params,model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        # 評価\n",
    "        if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "            avg_loss = total_loss / loss_count\n",
    "            print('| epoch %d |  iter %d / %d | loss %.2f'\n",
    "                  % (current_epoch + 1, iters + 1, max_iters, avg_loss))\n",
    "            loss_list.append(float(avg_loss))\n",
    "            total_loss, loss_count = 0, 0\n",
    "    current_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lJRQNjMfqhW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(loss_list)), loss_list)\n",
    "plt.xlabel(\"#iter\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkw99RcHfqhX"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bqlM7bvfqhY"
   },
   "outputs": [],
   "source": [
    "if loss_list[-1] > 1.1:\n",
    "    print(\"Seq2seqの実装に間違いがあります。問4を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。提出してください\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day5演習.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
