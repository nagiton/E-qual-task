{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "下記のコードをベースとして、LSTM、BiLSTM、attentionを使ったNMTモデルを構築し、BLEUスコアを算出する。\n",
    "https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "\n",
    "本ノートブックはそのうちLSTMを実装したものになる。\n",
    "\n",
    "# 処理の流れ\n",
    "0. 環境構築\n",
    "1. データのロード\n",
    "2. データの前処理\n",
    "3. モデルの定義\n",
    "    1. encoder\n",
    "    2. attention\n",
    "    3. decorder\n",
    "4. BLEUスコア評価用関数の定義\n",
    "5. 学習\n",
    "6. attentionの可視化\n",
    "\n",
    "# 前提\n",
    "課題であるsmall_parallel_enjaをgit cloneしたものを同じディレクトリに置く。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 環境構築\n",
    "本ノートブックはAWS Sagemakerのノートブックインスタンスでの動作を想定している。\n",
    "* kernel: conda_tensorflow_p36\n",
    "* instance type: ml.p2.xlarge(学習時), ml.t2.medium(開発時)\n",
    "\n",
    "また、tensorflow 2.1.0を使うため、下記のセルでアップデートを行う。\n",
    "\n",
    "アップデート後はkernel restartが必要。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "%%bash\n",
    "pip install --upgrade tensorflow\n",
    "pip install --upgrade tensorflow-gpu\n",
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16729067027528957028, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 4485317854231021275\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8928686706943236407\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11330115994\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16072224726026283728\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記を確認する。\n",
    "* print(tf.\\_\\_version\\_\\_)の出力が2.1.0であること\n",
    "* 学習を行う場合はdevice_lib.list_local_devices()の出力にGPUが含まれること\n",
    "* tf.executing_eagerly()がTrueになっており、eager executionが可能になっていること"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ファイルのダウンロード\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. データのロード\n",
    "* 前提として、ノートブックと課題であるsmall_parallel_enjaをgit cloneしたものを同じディレクトリに置く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユニコードファイルを ascii に変換\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # 文の開始と終了のトークンを付加\n",
    "    # モデルが予測をいつ開始し、いつ終了すれば良いかを知らせるため\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i can 't tell who will arrive first . <end>\n",
      "<start> 誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。 <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = \"i can 't tell who will arrive first .\"\n",
    "ja_sentence = \"誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(ja_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    with open(path) as f:\n",
    "        word_pairs = f.readlines()\n",
    "    word_pairs = [preprocess_sentence(sentence) for sentence in word_pairs]\n",
    "\n",
    "    return word_pairs[:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> he thought irritably . <end>\n",
      "<start> 彼 は いらだ ち ながら 思 っ た 。 <end>\n"
     ]
    }
   ],
   "source": [
    "# データの読み込み\n",
    "path_train_en = 'small_parallel_enja/train.en'\n",
    "path_train_ja = 'small_parallel_enja/train.ja'\n",
    "en = create_dataset(path_train_en, None)\n",
    "ja = create_dataset(path_train_ja, None)\n",
    "print(en[-1])\n",
    "print(ja[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<start> i can 't tell who will arrive first . <end>\",\n",
       " '<start> many animals have been destroyed by men . <end>',\n",
       " \"<start> i 'm in the tennis club . <end>\",\n",
       " '<start> emi looks happy . <end>',\n",
       " '<start> please bear this fact in mind . <end>',\n",
       " '<start> she takes care of my children . <end>',\n",
       " '<start> we want to be international . <end>',\n",
       " '<start> you ought not to break your promise . <end>',\n",
       " '<start> when you cross the street , watch out for cars . <end>',\n",
       " '<start> i have nothing to live for . <end>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. データの前処理\n",
    "通常、言語データを時系列データとして解析する際は、以下のようなステップをたどる\n",
    "1. 文字列の読み込み\n",
    "2. 単語単位への分解\n",
    "3. 単語へのID割り振り\n",
    "4. 単語列からIDの羅列への変換\n",
    "\n",
    "今回のデータセットは単語単位への分解がすでに終わっているので省略できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # クリーニングされた入力と出力のペアを生成\n",
    "    lang = create_dataset(path, num_examples)\n",
    "\n",
    "    tensor, lang_tokenizer = tokenize(lang)\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語へのIDの割り振りとID列への変換\n",
    "# このサイズのデータセットで実験\n",
    "num_examples = None\n",
    "input_tensor, inp_lang = load_dataset(path_train_en, num_examples)\n",
    "target_tensor, targ_lang = load_dataset(path_train_ja, num_examples)\n",
    "# ターゲットテンソルの最大長を計算\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 40000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "# 80-20で分割を行い、訓練用と検証用のデータセットを作成\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 長さを表示\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "44 ----> don\n",
      "20 ----> 't\n",
      "76 ----> work\n",
      "246 ----> yourself\n",
      "112 ----> too\n",
      "150 ----> hard\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "250 ----> あまり\n",
      "970 ----> 無理\n",
      "39 ----> する\n",
      "13 ----> な\n",
      "35 ----> よ\n",
      "4 ----> 。\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. モデルの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの処理の流れは下記\n",
    "1. Encorderで入力をhidden stateに変換\n",
    "    1. 入力された単語IDをembedding\n",
    "    2. LSTMでhidden stateに変換\n",
    "2. Decorderで文字列として出力\n",
    "    1. 前時刻のdecorder outputとhidden stateをLSTMでhidden stateに変換\n",
    "    2. 全結合層で単語に出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(128), Dimension(18)]),\n",
       " TensorShape([Dimension(128), Dimension(18)]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden, memory):\n",
    "        x = self.embedding(x)\n",
    "        output, memory, state = self.lstm(x, initial_state = [hidden,memory])\n",
    "        return output, memory, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return [tf.zeros((self.batch_sz, self.enc_units)),tf.zeros((self.batch_sz, self.enc_units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, units) (128, 1024)\n",
      "Encoder memory shape: (batch size, units) (128, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 1024)\n"
     ]
    }
   ],
   "source": [
    "# サンプル入力\n",
    "sample_hidden, sample_memory = encoder.initialize_hidden_state()\n",
    "sample_output, sample_memory, sample_state = encoder(example_input_batch, sample_hidden, sample_memory)\n",
    "print ('Encoder output shape: (batch size, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder memory shape: (batch size, units) {}'.format(sample_memory.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units,\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # アテンションのため\n",
    "        #self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, memory):\n",
    "        # enc_output の shape == (batch_size, max_length, hidden_size)\n",
    "        #context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        #x = tf.concat([tf.expand_dims(hidden, 1), x], axis=-1)\n",
    "\n",
    "        # 結合したベクトルを GRU 層に渡す\n",
    "        output, memory, state = self.lstm(x, initial_state = [hidden,memory])\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        #output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, memory, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 8778)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((128, 1)), sample_hidden, tf.zeros((BATCH_SIZE, units)))\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習途中段階のモデルはS3に保存した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 's3://e-qual-task/0202-LSTM/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://e-qual-task/0202-LSTM/ckpt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden, enc_memory):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_memory, enc_hidden = encoder(inp, enc_hidden, enc_memory)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        dec_memory = tf.zeros((BATCH_SIZE, units))\n",
    "\n",
    "        # Teacher Forcing - 正解値を次の入力として供給\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_memory, dec_hidden = decoder(dec_input, dec_hidden, dec_memory)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Teacher Forcing を使用\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BLEUスコア評価用関数の定義\n",
    "1. NMTモデルを使って英→日の翻訳\n",
    "2. テストデータを使ってモデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    #attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = []\n",
    "    for i in sentence.split(' '):\n",
    "        try:\n",
    "            inputs.append(inp_lang.word_index[i])\n",
    "        except KeyError:\n",
    "            inputs.append(inp_lang.word_index['<unk>'])\n",
    "\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = tf.zeros((1, units))\n",
    "    memory = tf.zeros((1, units))\n",
    "    #inputs = tf.expand_dims(inputs,0)\n",
    "    enc_out, enc_memory, enc_hidden  = encoder(inputs, hidden, memory)\n",
    "\n",
    "    #return enc_hidden\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    dec_memory = tf.zeros((1, units))\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_memory, dec_hidden = decoder(dec_input, dec_hidden, dec_memory)\n",
    "        '''\n",
    "        # 後ほどプロットするためにアテンションの重みを保存\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        '''\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence\n",
    "\n",
    "        # 予測された ID がモデルに戻される\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# アテンションの重みをプロットする関数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence= evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    #plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用にtestデータをロードしておく\n",
    "path_test_en = 'small_parallel_enja/test.en'\n",
    "with open(path_test_en) as f:\n",
    "    en_test = f.readlines()\n",
    "en_test = [w.rstrip().strip() for w in en_test]\n",
    "    \n",
    "path_test_ja = 'small_parallel_enja/test.ja'\n",
    "with open(path_test_ja) as f:\n",
    "    ja_test = f.readlines()\n",
    "ja_test = [w.rstrip().strip() for w in ja_test]\n",
    "ja_test = ja_test[:100]\n",
    "# BLEUのライブラリのインプットにデータ形式をあわせる\n",
    "ja_test_l = [sentence.split() for sentence in ja_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習中に呼び出してモニタリングするために関数化\n",
    "def calc_BLEU(pred_l,test_l):\n",
    "    score = [sentence_bleu([reference], candidate) for reference, candidate in zip(test_l,pred_l )]\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEUの警告がうるさいので静かにさせる\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 学習\n",
    "学習は20エポック行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1 Batch 0 Loss 6.0297\n",
      "Epoch 1 Batch 100 Loss 3.0834\n",
      "Epoch 1 Batch 200 Loss 2.9004\n",
      "Epoch 1 Batch 300 Loss 2.6255\n",
      "Epoch 1 Loss 2.9881 BLEU score 0.0000\n",
      "Time taken for 1 epoch 203.34967756271362 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.4523\n",
      "Epoch 2 Batch 100 Loss 2.4127\n",
      "Epoch 2 Batch 200 Loss 2.4045\n",
      "Epoch 2 Batch 300 Loss 2.2972\n",
      "Epoch 2 Loss 2.3607 BLEU score 0.0027\n",
      "Time taken for 1 epoch 145.85645365715027 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.1705\n",
      "Epoch 3 Batch 100 Loss 2.2081\n",
      "Epoch 3 Batch 200 Loss 2.2357\n",
      "Epoch 3 Batch 300 Loss 2.1747\n",
      "Epoch 3 Loss 2.1796 BLEU score 0.0000\n",
      "Time taken for 1 epoch 134.0729637145996 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.0530\n",
      "Epoch 4 Batch 100 Loss 2.1103\n",
      "Epoch 4 Batch 200 Loss 2.1475\n",
      "Epoch 4 Batch 300 Loss 2.0977\n",
      "Epoch 4 Loss 2.0895 BLEU score 0.0040\n",
      "Time taken for 1 epoch 135.38746118545532 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.9733\n",
      "Epoch 5 Batch 100 Loss 2.0597\n",
      "Epoch 5 Batch 200 Loss 2.0929\n",
      "Epoch 5 Batch 300 Loss 2.0471\n",
      "Epoch 5 Loss 2.0327 BLEU score 0.0000\n",
      "Time taken for 1 epoch 431.4570903778076 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.9260\n",
      "Epoch 6 Batch 100 Loss 2.0121\n",
      "Epoch 6 Batch 200 Loss 2.0486\n",
      "Epoch 6 Batch 300 Loss 1.9997\n",
      "Epoch 6 Loss 1.9888 BLEU score 0.0000\n",
      "Time taken for 1 epoch 136.03940415382385 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.8808\n",
      "Epoch 7 Batch 100 Loss 1.9779\n",
      "Epoch 7 Batch 200 Loss 2.0070\n",
      "Epoch 7 Batch 300 Loss 1.9724\n",
      "Epoch 7 Loss 1.9531 BLEU score 0.0000\n",
      "Time taken for 1 epoch 133.96660089492798 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.8547\n",
      "Epoch 8 Batch 100 Loss 1.9498\n",
      "Epoch 8 Batch 200 Loss 1.9795\n",
      "Epoch 8 Batch 300 Loss 1.9473\n",
      "Epoch 8 Loss 1.9254 BLEU score 0.0000\n",
      "Time taken for 1 epoch 134.07759070396423 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.8232\n",
      "Epoch 9 Batch 100 Loss 1.9227\n",
      "Epoch 9 Batch 200 Loss 1.9524\n",
      "Epoch 9 Batch 300 Loss 1.9280\n",
      "Epoch 9 Loss 1.9008 BLEU score 0.0000\n",
      "Time taken for 1 epoch 136.55814266204834 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.7998\n",
      "Epoch 10 Batch 100 Loss 1.9031\n",
      "Epoch 10 Batch 200 Loss 1.9302\n",
      "Epoch 10 Batch 300 Loss 1.9067\n",
      "Epoch 10 Loss 1.8793 BLEU score 0.0000\n",
      "Time taken for 1 epoch 223.70321416854858 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.7740\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-eb21ad0e2685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "stats = dict.fromkeys(('Epoch','Loss','BLEU'))\n",
    "stats['Epoch'], stats['Loss'], stats['BLEU'] = [], [], []\n",
    "BLEU_score = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden, enc_memory = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden, enc_memory)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # 5 エポックごとにモデル（のチェックポイント）を保存\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    # エポックごとにBLEUスコアを評価\n",
    "    ja_pred = [evaluate(sentence)[0] for sentence in en_test[:100]]\n",
    "    ja_pred_l = [sentence.split() for sentence in ja_pred]\n",
    "    BLEU_score = calc_BLEU(ja_pred_l, ja_test_l)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f} BLEU score {:.4f}'.format(epoch + 1,\n",
    "                                                          total_loss / steps_per_epoch,\n",
    "                                                          BLEU_score))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    stats['Epoch'].append(epoch + 1)\n",
    "    stats['Loss'].append(total_loss / steps_per_epoch)\n",
    "    stats['BLEU'].append(BLEU_score)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint.save(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ckpt/ckpt_0202/LSTM/-3'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.save('ckpt/ckpt_0202/LSTM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(stats)\n",
    "df['Loss'] = df['Loss'].map(lambda x:x.numpy())\n",
    "df.to_csv('LSTM-0202.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 評価と可視化\n",
    "得られたスコアをプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa0564a8128>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_dir の中の最後のチェックポイントを復元\n",
    "#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "checkpoint.restore(tf.train.latest_checkpoint('ckpt/ckpt_0201/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff682d2ec50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['Loss','Epoch']].plot('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff6814b7940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['BLEU','Epoch']].plot('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grand truth: 彼 ら は つい に それ が 真実 だ と 認め た 。\n",
      "Input: <start> they finally acknowledged it as true . <end>\n",
      "Predicted translation: 彼 は 私 の 意見 は 私 に は な い 。 <end> \n"
     ]
    }
   ],
   "source": [
    "print('grand truth: 彼 ら は つい に それ が 真実 だ と 認め た 。')\n",
    "translate('they finally acknowledged it as true .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grand truth: 彼 は 水泳 が 得意 で は な かっ た 。\n",
      "Input: <start> he didn 't care for swimming . <end>\n",
      "Predicted translation: 彼 は 私 の 意見 は 私 に は な い 。 <end> \n"
     ]
    }
   ],
   "source": [
    "print('grand truth: 彼 は 水泳 が 得意 で は な かっ た 。')\n",
    "translate(\"he didn 't care for swimming .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grand truth: 彼 は お 姉 さん に 劣 ら ず 親切 だ 。\n",
      "Input: <start> he is no less kind than his sister . <end>\n",
      "Predicted translation: 彼 は 私 の 意見 は 私 に は な い 。 <end> \n"
     ]
    }
   ],
   "source": [
    "print('grand truth: 彼 は お 姉 さん に 劣 ら ず 親切 だ 。')\n",
    "translate('he is no less kind than his sister .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grand truth: １０ 時 前 に 戻 ら な けれ ば な ら な い 。\n",
      "Input: <start> you must be back before ten . <end>\n",
      "Predicted translation: 彼 は 私 の 意見 は 私 に は な い 。 <end> \n"
     ]
    }
   ],
   "source": [
    "print('grand truth: １０ 時 前 に 戻 ら な けれ ば な ら な い 。')\n",
    "translate('you must be back before ten .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grand truth: １０ 時 前 に 戻 ら な けれ ば な ら な い 。\n",
      "Input: <start> . <end>\n",
      "Predicted translation: 彼 は 私 の 意見 は 私 に は な い 。 <end> \n"
     ]
    }
   ],
   "source": [
    "print('grand truth: １０ 時 前 に 戻 ら な けれ ば な ら な い 。')\n",
    "translate(' .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'彼 は 私 の 意見 は 私 に は な い 。 <end> '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('you must be back before ten .')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1884819, shape=(1024,), dtype=float32, numpy=\n",
       "array([ 0.41313547, 15.146737  , -0.42926496, ...,  0.        ,\n",
       "        0.5459836 , 14.960977  ], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('you .')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1886447, shape=(1024,), dtype=float32, numpy=\n",
       "array([ 0.43178654, 15.137441  , -0.42651835, ...,  0.        ,\n",
       "        0.54773426, 14.958078  ], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"he didn 't care for swimming .\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063349724"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(evaluate('you you you you you .')[0].numpy()-evaluate('you must be back before ten .')[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
